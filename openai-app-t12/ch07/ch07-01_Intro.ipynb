{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-17T05:56:20.585540Z",
     "start_time": "2025-11-17T05:56:19.533712Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain_core import chat_history\n",
    "\n",
    "load_dotenv(\"../../_apikeys.env\")\n",
    "api_key = os.getenv(\"DoogieOpenaiKey\")\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import gradio as gr",
   "id": "8ee2f718a0a00649",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T03:51:42.291334Z",
     "start_time": "2025-11-13T03:51:40.479151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 1-1: get test documents\n",
    "#\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/chatgpt-kr/openai-api-tutorial/raw/main/ch07/2020_%EA%B2%BD%EC%A0%9C%EA%B8%88%EC%9C%B5%EC%9A%A9%EC%96%B4%20700%EC%84%A0_%EA%B2%8C%EC%8B%9C.pdf\", filename=\"07_01_EcoKeyword.pdf\")"
   ],
   "id": "9d98da4f199d4347",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('07_01_EcoKeyword.pdf', <http.client.HTTPMessage at 0x108edc9d0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:56:41.394495Z",
     "start_time": "2025-11-17T05:56:25.447832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 1-2: load and split PDF\n",
    "# 17~20 sec\n",
    "#\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader( \"07_01_EcoKeyword.pdf\" )\n",
    "pages = loader.load_and_split()  # about 17s\n",
    "print('Load and Splits Docs: ', len(pages) )\n",
    "#pages = loader.load()  # about 16s, include empty page\n"
   ],
   "id": "11a032cbbda8f39b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and Splits Docs:  366\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Load and Splits Docs: ', len(pages) )\n",
    "print('some Docs[0]: ', pages[0].page_content[:100])\n",
    "print('some Docs[5]: ', pages[5].page_content[:100])\n",
    "print('some Docs[12]: ', pages[12].page_content[:100])\n",
    "print('some Docs[13]: ', pages[13].page_content[:100])\n",
    "print('some Docs[15]: ', pages[15].page_content[:100])"
   ],
   "id": "44738b73f61a5dbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:56:48.284453Z",
     "start_time": "2025-11-17T05:56:48.280012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 1-3: remove 1~12 and last of chunks\n",
    "#\n",
    "pageBodys = pages[13:]\n",
    "print('pageBodys: ', len(pageBodys) )\n",
    "#print('pageBodys[0]: ', pageBodys[0].page_content[:100]) # was 13\n",
    "#print('pageBodys[2]: ', pageBodys[2].page_content[:100]) # was 15\n",
    "#print('pageBodys[-1]: ', pageBodys[-1].page_content[:100]) # was last\n",
    "pageBodys = pageBodys[:-1]\n",
    "print('pageBodys: ', len(pageBodys) )\n",
    "#print('pageBodys[-1]: ', pageBodys[-1].page_content[:100]) # was last"
   ],
   "id": "1e58f8edff0bcd86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pageBodys:  353\n",
      "pageBodys:  352\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:56:55.164212Z",
     "start_time": "2025-11-17T05:56:53.740968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step2-1: using package 'langchain_openai', not 'OpenAIEmbeddings'\n",
    "#          from langchain.embeddings import OpenAIEmbeddings\n",
    "#          'langchain.embeddings' deprecated, use 'langchain_openai'\n",
    "#\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "myEmbeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "print(\"current OpenAIEmbeddings().model=\", myEmbeddings.model)\n",
    "\n",
    "persist_dir = \"../localdb/my_chroma07_01\"\n",
    "myCollectionName = \"my_collection\""
   ],
   "id": "e169a8af7467c08b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current OpenAIEmbeddings().model= text-embedding-3-large\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# CAN NOT USE THIS STYLE with Over Token Max\n",
    "# Step2-2: load chromaDB with pageBodys, by one Method\n",
    "#\n",
    "os.environ[\"CHROMA_TELEMETRY\"] = \"False\"\n",
    "#from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vdb = Chroma.from_documents(\n",
    "    pageBodys,\n",
    "    embedding=myEmbeddings,\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name=myCollectionName\n",
    ")\n",
    "\n",
    "print(vdb._collection.count())"
   ],
   "id": "e541ed2dc4cbeddf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:57:23.996641Z",
     "start_time": "2025-11-17T05:57:06.470483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step2-2: load chromaDB with pageBodys, by splited Method\n",
    "#\n",
    "os.environ[\"CHROMA_TELEMETRY\"] = \"False\"\n",
    "#from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vdb = Chroma(\n",
    "    embedding_function=myEmbeddings,\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name=myCollectionName\n",
    ")\n",
    "\n",
    "def clear_before_addDoc():\n",
    "    global vdb\n",
    "    all_ids = vdb.get()[\"ids\"]\n",
    "\n",
    "    if ( len(all_ids) == 0 ):\n",
    "        print(\">> vdb size = 0 ì´ë¯€ë¡œ collection delete í•˜ì§€ ì•ŠìŒ.\")\n",
    "        return\n",
    "\n",
    "    # ì»¬ë ‰ì…˜ ë‚´ë¶€ ë°ì´í„° ì „ì²´ ì‚­ì œ\n",
    "    print(f\">> vdb size = {len(all_ids)}, ë²¡í„° ì»¬ë ‰ì…˜ ë°ì´í„° ì‚­ì œ ì‹œì‘...\", end=\"\")\n",
    "    try:\n",
    "        vdb._collection.delete(ids=all_ids)\n",
    "        print(\"++ë²¡í„° ì»¬ë ‰ì…˜ ë°ì´í„° ì‚­ì œ ì™„ë£Œ.\")\n",
    "    except Exception as e:\n",
    "        print(\"++ë²¡í„° ì»¬ë ‰ì…˜ ì‚­ì œ ì‹¤íŒ¨:\", e)\n",
    "    print(\">> vdb size = \", len( vdb.get()[\"ids\"] ) )\n",
    "\n",
    "def process_in_batches(documents, batch_size=100, reset_db=True):\n",
    "    global vdb\n",
    "\n",
    "    # -- ì§‘ì–´ ë„£ì„ ë¬¸ì„œ í™•ì¸ --\n",
    "    splitedDocsLen = len(documents)\n",
    "    print(\">> ready to insert splitedDocs, len = \", splitedDocsLen)\n",
    "\n",
    "    if splitedDocsLen == 0:\n",
    "        print(\">> ì²˜ë¦¬í•  splitedDocsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. batchì²˜ë¦¬ ì¤‘ì§€...\")\n",
    "        return 0\n",
    "\n",
    "    # -- ë¬¸ì„œ í¬ê¸°ë¥¼ batch_sizeë¡œ ë‚˜ëˆ„ì–´ í™•ì¸í•˜ê¸°\n",
    "    batchCount = splitedDocsLen // batch_size\n",
    "    if splitedDocsLen % batch_size > 0:\n",
    "        batchCount += 1\n",
    "    print(\">> batchsize is \", batch_size, \"and batchCount:\", batchCount)\n",
    "\n",
    "    # -- ë¬¸ì„œë¥¼ batch_sizeë¡œ ì˜ë¼ì„œ ì§‘ì–´ ë„£ê¸°\n",
    "    for i, batch in enumerate(range(0, splitedDocsLen, batch_size)):\n",
    "        print(\">>\", i, \"th batch, \", batch, \"..\", batch + batch_size - 1, end=\"\")\n",
    "        batchDocs = documents[batch:batch + batch_size]\n",
    "        vdb.add_documents(batchDocs)\n",
    "        print(\" ++ added batchDocs len:\", len(batchDocs))\n",
    "    print(\">> process_in_batch() >> vdb size:\", len( vdb.get()[\"ids\"] ))\n",
    "\n",
    "print(\"[START] vdb í¬ê¸°=\", len( vdb.get()[\"ids\"] ) )\n",
    "print(\">>Persist Dir:\", persist_dir)\n",
    "print(\">>myCollectionName:\", myCollectionName)\n",
    "print(\">> vdb._collectiob.count(): \",vdb._collection.count())\n",
    "\n",
    "clear_before_addDoc()\n",
    "process_in_batches(pageBodys)\n",
    "\n",
    "print(\"[END] vdb í¬ê¸°=\", len( vdb.get()[\"ids\"] ) )\n",
    "print(\"[END] vdb._collectiob.count(): \",vdb._collection.count())"
   ],
   "id": "970443d38dba69d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] vdb í¬ê¸°= 352\n",
      ">>Persist Dir: ../localdb/my_chroma07_01\n",
      ">>myCollectionName: my_collection\n",
      ">> vdb._collectiob.count():  352\n",
      ">> vdb size = 352, ë²¡í„° ì»¬ë ‰ì…˜ ë°ì´í„° ì‚­ì œ ì‹œì‘...++ë²¡í„° ì»¬ë ‰ì…˜ ë°ì´í„° ì‚­ì œ ì™„ë£Œ.\n",
      ">> vdb size =  0\n",
      ">> ready to insert splitedDocs, len =  352\n",
      ">> batchsize is  100 and batchCount: 4\n",
      ">> 0 th batch,  0 .. 99 ++ added batchDocs len: 100\n",
      ">> 1 th batch,  100 .. 199 ++ added batchDocs len: 100\n",
      ">> 2 th batch,  200 .. 299 ++ added batchDocs len: 100\n",
      ">> 3 th batch,  300 .. 399 ++ added batchDocs len: 52\n",
      ">> process_in_batch() >> vdb size: 352\n",
      "[END] vdb í¬ê¸°= 352\n",
      "[END] vdb._collectiob.count():  352\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:57:29.465679Z",
     "start_time": "2025-11-17T05:57:28.916381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\">> vdb í¬ê¸°=\", len( vdb.get()[\"ids\"] ) )\n",
    "print(\">> vdb._collection.count(): \",vdb._collection.count())\n",
    "print(\">> Persist Dir:\", persist_dir)\n",
    "print(\">> myCollectionName:\", myCollectionName)\n",
    "\n",
    "for key in vdb._collection.get():\n",
    "    #print(key, vdb._collection.get()[key][:100])\n",
    "    #print(key, vdb.get()[key][:100])\n",
    "    if ( vdb.get()[key] is None ):\n",
    "        print(key, \"is None\")\n",
    "    else:\n",
    "        print(key, len(vdb.get()[key]))"
   ],
   "id": "224afae34fe58082",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> vdb í¬ê¸°= 352\n",
      ">> vdb._collection.count():  352\n",
      ">> Persist Dir: ../localdb/my_chroma07_01\n",
      ">> myCollectionName: my_collection\n",
      "ids 352\n",
      "embeddings is None\n",
      "documents 352\n",
      "uris is None\n",
      "included 2\n",
      "data is None\n",
      "metadatas 352\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:57:35.906308Z",
     "start_time": "2025-11-17T05:57:35.859081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 2-3: load documents from vdb(chromadb)\n",
    "#\n",
    "docsFromVdb = vdb.get()['documents']\n",
    "print(\"chunk length of fromVdb: \", len(docsFromVdb) )\n",
    "print(\"fromVdb[0]: \", docsFromVdb[0][:100])\n"
   ],
   "id": "309fd17d117887c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk length of fromVdb:  352\n",
      "fromVdb[0]:  1\n",
      "ã„± \n",
      "ã„±\n",
      "ê°€ê³„ë¶€ì‹¤ìœ„í—˜ì§€ìˆ˜(HDRI)\n",
      "ê°€êµ¬ì˜ ì†Œë“ íë¦„ì€ ë¬¼ë¡  ê¸ˆìœµ ë° ì‹¤ë¬¼ ìì‚°ê¹Œì§€ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ê°€ê³„ë¶€ì±„ì˜ \n",
      "ë¶€ì‹¤ìœ„í—˜ì„ í‰ê°€í•˜ëŠ” ì§€í‘œë¡œ, ê°€ê³„ì˜ ì±„ë¬´ìƒí™˜ëŠ¥ë ¥ì„ ì†Œë“ ì¸¡ë©´\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"ids: \",          len(vdb.get()['ids']) )\n",
    "print(\"ids: \",          len(vdb.get()['ids'][0]), \">>\", vdb.get()['ids'][0] )\n",
    "print(\"embeddings: \",   vdb.get()['embeddings'] )\n",
    "print(\"uris: \",         vdb.get()['uris'] )\n",
    "print(\"included: \",     vdb.get()['included'] )\n",
    "print(\"data: \",         vdb.get()['data'] )\n",
    "print(\"metadatas: \",    len( vdb.get()['metadatas']) )\n",
    "print(\"metadatas: \",    vdb.get()['metadatas'][0] )\n",
    "print(\"documents: \",    len( vdb.get()['documents']) )\n",
    "print(\"documents: \",    vdb.get()['documents'][0][:100] )"
   ],
   "id": "f87f1054b7aada8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step2-4: get vdb's embeddings >> direct to 'embeddings' key\n",
    "#\n",
    "vdbEmbeddings = vdb.get(include=['embeddings'])['embeddings']\n",
    "print('len embedding from vdb: ', len(vdbEmbeddings) )\n",
    "print('len(vdbEmbeddings[0]): ', len(vdbEmbeddings[0]) )\n",
    "print('vdbEmbeddings[0]: ', vdbEmbeddings[0][:100] )\n"
   ],
   "id": "551f9c00fcef7816",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:57:56.197041Z",
     "start_time": "2025-11-17T05:57:55.222948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 3-1: retriever from vdb with question's similarity at RAG documents\n",
    "# searchRetriever from vdb, is USE for RADIO chat's RAG\n",
    "#\n",
    "searchRetriever = vdb.as_retriever( search_kwargs={\"k\": 3} )\n",
    "#searchResult = searchRetriever.get_relevant_documents(\"ë¹„íŠ¸ì½”ì¸ì´ ê¶ê¸ˆí•´\")\n",
    "searchResult = searchRetriever.invoke(\"ë¹„íŠ¸ì½”ì¸ì´ ê¶ê¸ˆí•´\")\n",
    "\n",
    "print('result docs: ',  len(searchResult) )\n",
    "for i in range(len(searchResult)):\n",
    "    print(f'result docs[{i}]: ',   searchResult[i].page_content[:100] )"
   ],
   "id": "ac87eb9c72221f21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result docs:  3\n",
      "result docs[0]:  139\n",
      "ã…‚ \n",
      "ë¹„íŠ¸ì½”ì¸\n",
      "ë¹„íŠ¸ì½”ì¸(bitcoin)ì€ ê°€ìƒí†µí™”(ì•”í˜¸í†µí™”)ì´ì ë””ì§€í„¸ ì§€ê¸‰ì‹œìŠ¤í…œì´ë‹¤. ë¹„íŠ¸ì½”ì¸ ì‹œìŠ¤í…œ\n",
      "ì€ ì¤‘ì•™ ì €ì¥ì†Œ ë˜ëŠ” ë‹¨ì¼ ê´€ë¦¬ìê°€ ì—†ê¸° ë•Œë¬¸ì— ìµœì´ˆì˜ íƒˆì¤‘ì•™í™”ëœ ë””\n",
      "result docs[1]:  5\n",
      "ã„± \n",
      "ê°€ì‚°ê¸ˆë¦¬\n",
      "ê¸°ì¤€ê¸ˆë¦¬ì— ì‹ ìš©ë„ ë“±ì˜ ì°¨ì´ì— ë”°ë¼ ë‹¬ë¦¬ ë§ë¶™ì´ëŠ” ê¸ˆë¦¬ë¥¼ ê°€ì‚°ê¸ˆë¦¬(ë˜ëŠ” ìŠ¤í”„ë ˆë“œ, \n",
      "spread)ë¼ê³  í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì€í–‰ì´ ëŒ€ì¶œê¸ˆë¦¬ë¥¼ ê²°ì •í•  ë•Œ ê³ ê°ì˜ ì‹ ìš©ìœ„\n",
      "result docs[2]:  136\n",
      "ê²½ì œê¸ˆìœµìš©ì–´ 700ì„ \n",
      "ê°„ ëŒ€í™”ì˜ ê¹Šì´ì™€ í­ë„ ë”ìš± ë„“ì–´ì§€ê³  ìˆë‹¤. ë¸Œë¦­ìŠ¤ëŠ” í˜„ì¬ì˜ ê²½ì œì„±ì¥ ì†ë„ì™€ ì•ìœ¼ë¡œì˜ \n",
      "ë°œì „ ì „ë§ì— ë¹„ì¶”ì–´ ì‹ í¥ ê²½ì œëŒ€êµ­ìœ¼ë¡œ ë°œë‹ì›€í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ ë‚˜\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:58:43.606776Z",
     "start_time": "2025-11-17T05:58:43.481381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 4-1: query to GPT, with RAG similar docs\n",
    "#\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "myTemplate = \"\"\"\n",
    "ë‹¹ì‹ ì€ í•œêµ­ì€í–‰ì—ì„œ ë§Œë“  ê¸ˆìœµìš©ì–´ë¥¼ ì„¤ëª…í•´ ì£¼ëŠ” ê¸ˆìœµë„ìš°ë¯¸ ì…ë‹ˆë‹¤.\n",
    "Emmaê°€ ê°œë°œí•˜ì—¬ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.\n",
    "ì£¼ì–´ì§„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´, ê·¸ë˜ë„ ìµœëŒ€í•œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "{context}\n",
    "\n",
    "Question\" {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "# myPrompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=myTemplate)\n",
    "myPrompt = PromptTemplate.from_template(myTemplate)\n",
    "\n",
    "myLLM = ChatOpenAI(\n",
    "    model_name = \"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "myChain = RetrievalQA.from_chain_type(\n",
    "    llm=myLLM,\n",
    "    chain_type=\"stuff\",  ###\n",
    "    retriever=searchRetriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": myPrompt},\n",
    "    # verbose=True, ###\n",
    ")"
   ],
   "id": "fba2a1c02642d64c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:58:52.125043Z",
     "start_time": "2025-11-17T05:58:46.044274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"ë””ì»¤í”Œë§ì´ë€ ë¬´ì—‡ì¸ê°€?\"\n",
    "#reChatChain = myChain({\"question\": question})\n",
    "#reChatChain = myChain(question) # deprecate, old style\n",
    "reChatChain = myChain.invoke(question)\n",
    "print(\"resultChatbotChain size: \", len(reChatChain) )"
   ],
   "id": "cdb07b39acdd6559",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultChatbotChain size:  3\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:58:54.299914Z",
     "start_time": "2025-11-17T05:58:54.293814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 4-2: checkup result\n",
    "#\n",
    "print(reChatChain[\"query\"])\n",
    "print(reChatChain[\"result\"])\n",
    "\n",
    "for i in range(len(reChatChain[\"source_documents\"])):\n",
    "    print(f\"src_docs[{i}].page: \", reChatChain[\"source_documents\"][i].metadata[\"page_label\"])\n",
    "    print(f\"src_docs[{i}].body: \", reChatChain[\"source_documents\"][i].page_content[:100] )"
   ],
   "id": "f39b6c30f1ba8036",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë””ì»¤í”Œë§ì´ë€ ë¬´ì—‡ì¸ê°€?\n",
      "ë””ì»¤í”Œë§(decoupling)ì€ íƒˆë™ì¡°í™”ë¼ëŠ” ì˜ë¯¸ë¡œ, íŠ¹ì • êµ­ê°€ë‚˜ ì§€ì—­ì˜ ê²½ì œê°€ ì¸ì ‘í•œ ë‹¤ë¥¸ êµ­ê°€ë‚˜ ì „ë°˜ì ì¸ ì„¸ê³„ ê²½ì œì˜ íë¦„ê³¼ëŠ” ë‹¤ë¥¸ ì–‘ìƒì„ ë³´ì´ëŠ” í˜„ìƒì„ ë§í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸ˆìœµìœ„ê¸° ì´í›„ ì‹ í¥êµ­ê°€ë‚˜ ìœ ë¡œì§€ì—­ êµ­ê°€ë“¤ì´ ë¯¸êµ­ ê²½ì œì™€ ë‹¤ë¥¸ ëª¨ìŠµì„ ë³´ì´ëŠ” ê²½ìš°ê°€ ë””ì»¤í”Œë§ì˜ í•œ ì˜ˆì…ë‹ˆë‹¤. ë˜í•œ, ì£¼ê°€, ê¸ˆë¦¬, í™˜ìœ¨ ë“± ì¼ë¶€ ê²½ì œ ë³€ìˆ˜ì˜ íë¦„ì´ êµ­ê°€ ê°„ ë˜ëŠ” íŠ¹ì • êµ­ê°€ ë‚´ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë°©í–¥ìœ¼ë¡œ ì›€ì§ì´ëŠ” ê²½ìš°ë„ ë””ì»¤í”Œë§ìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, í•œ ë‚˜ë¼ ë˜ëŠ” ì§€ì—­ì˜ ê²½ì œê°€ ì¸ì ‘í•œ ë‹¤ë¥¸ êµ­ê°€ë‚˜ ì„¸ê³„ ê²½ì œì˜ íë¦„ê³¼ ìœ ì‚¬í•œ ë°©í–¥ìœ¼ë¡œ ì›€ì§ì´ëŠ” í˜„ìƒì€ ì»¤í”Œë§(coupling)ì´ë¼ê³  í•©ë‹ˆë‹¤.\n",
      "src_docs[0].page:  115\n",
      "src_docs[0].body:  98\n",
      "ê²½ì œê¸ˆìœµìš©ì–´ 700ì„ \n",
      "ê°€ê³„ì™€ ê¸°ì—…ì´ ì†Œë¹„ì™€ íˆ¬ìë¥¼ ë¯¸ë£¸ìœ¼ë¡œì¨ ìˆ˜ìš”ì˜ ìœ„ì¶•ì„ ì´ˆë˜í•˜ì—¬ ë””í”Œë ˆì´ì…˜ ì••ë ¥ì„ \n",
      "ë³´ë‹¤ í¬ê²Œ í•  ìˆ˜ë„ ìˆë‹¤. ì´ ê°™ì€ ìƒí™©ì—ì„œëŠ” ê²½ì œì£¼ì²´ë“¤ì˜ ë¬¼ê°€ìƒìŠ¹ë¥  \n",
      "src_docs[1].page:  106\n",
      "src_docs[1].body:  89\n",
      "ã„· \n",
      "ìœ ì§€í•œ ì±„ ì›ë¦¬ê¸ˆ ìˆ˜ì·¨ê¶Œë§Œì„ ì–‘ë„í•˜ê²Œ ë˜ì–´ ìˆì–´ ì°¸ê°€ìê°€ ëŒ€ì¶œì±„ê¶Œì— ëŒ€í•œ ìœ„í—˜ì„ \n",
      "ë¶€ë‹´í•˜ê²Œ ëœë‹¤. ì¦‰ ê¸ˆìœµê¸°ê´€ì´ ì±„ë¬´ìë¡œë¶€í„° ì›ë¦¬ê¸ˆì„ íšŒìˆ˜í•˜ëŠ” ê²½ìš°ì— í•œí•˜ì—¬ ì›ë¦¬ê¸ˆì„ \n",
      "\n",
      "src_docs[2].page:  184\n",
      "src_docs[2].body:  167\n",
      "ã…… \n",
      "ê°ì†Œë¡œ ë¹„ìš©ì´ ë‚®ì•„ì§€ë©°, íˆ¬ëª…ì„±ë„ í–¥ìƒë˜ì–´ ì‹ ë¢°ë„ê°€ ë†’ì•„ì§ìœ¼ë¡œì¨ ë” ì•ˆì „í•˜ê²Œ ê³„ì•½ì´ \n",
      "ì‹¤í–‰ë  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´ ì†í•´ë³´í—˜ ë³´ìƒì—…ë¬´ì˜ ê²½ìš° ë³´í—˜ê°€ì…ìï½¥ë³´í—˜ì‚¬ï½¥ì†í•´ì‚¬ì •ì¸\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T05:59:00.363465Z",
     "start_time": "2025-11-17T05:58:58.394216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"ë„ˆëŠ” ëˆ„ê°€ ê°œë°œí–ˆëŠ”ê°€?\"\n",
    "#question = \"ë„ˆëŠ” ë¬´ì—‡ì„ í•˜ëŠ” ì±—ë´‡ì´ë‹ˆ?\"\n",
    "reChatChain = myChain.invoke(question)\n",
    "print(\"result len: \", len(reChatChain[\"source_documents\"]) )\n",
    "print(reChatChain[\"result\"])\n",
    "for i in range(len(reChatChain[\"source_documents\"])):\n",
    "    print(f\"src_docs[{i}].body: \", reChatChain[\"source_documents\"][i].page_content[:100] )"
   ],
   "id": "6aeb09f4cf08c052",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result len:  3\n",
      "ì €ëŠ” Emmaê°€ ê°œë°œí•œ ê¸ˆìœµë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n",
      "src_docs[0].body:  139\n",
      "ã…‚ \n",
      "ë¹„íŠ¸ì½”ì¸\n",
      "ë¹„íŠ¸ì½”ì¸(bitcoin)ì€ ê°€ìƒí†µí™”(ì•”í˜¸í†µí™”)ì´ì ë””ì§€í„¸ ì§€ê¸‰ì‹œìŠ¤í…œì´ë‹¤. ë¹„íŠ¸ì½”ì¸ ì‹œìŠ¤í…œ\n",
      "ì€ ì¤‘ì•™ ì €ì¥ì†Œ ë˜ëŠ” ë‹¨ì¼ ê´€ë¦¬ìê°€ ì—†ê¸° ë•Œë¬¸ì— ìµœì´ˆì˜ íƒˆì¤‘ì•™í™”ëœ ë””\n",
      "src_docs[1].body:  103\n",
      "ã„¹ \n",
      "ë¡œë³´ì–´ë“œë°”ì´ì €\n",
      "ë¡œë³´ì–´ë“œë°”ì´ì €(robo-advisor)ëŠ” ë¡œë´‡(robot)ê³¼ ìë¬¸ê°€(advisor)ì˜ í•©ì„±ì–´ì´ë‹¤. ì´ëŠ” \n",
      "ì¸ê³µì§€ëŠ¥ ì•Œê³ ë¦¬ì¦˜, ë¹…ë°ì´í„° ë“±ì„ í™œìš©í•˜ì—¬ íˆ¬ì\n",
      "src_docs[2].body:  183\n",
      "ã…‡ \n",
      "ì•„ì‹œì•„ê°œë°œì€í–‰(ADB)\n",
      "ì•„ì‹œì•„ï½¥íƒœí‰ì–‘ì§€ì—­ì˜ ê²½ì œì„±ì¥ ë° ê²½ì œí˜‘ë ¥ ì´‰ì§„ê³¼ ì—­ë‚´ ê°œë„êµ­ì˜ ê²½ì œê°œë°œ ì§€ì›ì„ \n",
      "ëª©ì ìœ¼ë¡œ 1966ë…„ 8ì›” ì„¤ë¦½ëœ êµ­ì œê¸ˆìœµê¸°êµ¬ë¡œì„œ í•„ë¦¬í•€ ë§ˆë‹ë¼ì—\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"ë¹„íŠ¸ì½”ì¸ì— ëŒ€í•´ì„œ ê¶ê¸ˆí•˜ë‹¹~~?\"\n",
    "#question = \"ë””ì»¤í”Œë§ì´ë€ ë¬´ì—‡ì¸ê°€?\"\n",
    "#reChatChain = myChain(question)\n",
    "reChatChain = myChain.invoke(question)\n",
    "print(\"result len: \", len(reChatChain[\"source_documents\"]) )\n",
    "print(reChatChain[\"result\"])\n",
    "for i in range(len(reChatChain[\"source_documents\"])):\n",
    "    print(f\"src_docs[{i}].body: \", reChatChain[\"source_documents\"][i].page_content[:100] )"
   ],
   "id": "753e7428a9497599",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T06:01:22.589649Z",
     "start_time": "2025-11-17T06:01:22.586032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# gradio version check\n",
    "# IMPORTANT: m\n",
    "#\n",
    "import gradio as gr\n",
    "print(gr.__version__)"
   ],
   "id": "d598edf533e6ee88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.50.2\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# gr.ChatInterface() í…ŒìŠ¤íŠ¸\n",
    "#\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def respond(message, history):\n",
    "    return f\"Echo: {message}\"\n",
    "\n",
    "demo = gr.ChatInterface(respond)\n",
    "demo.launch()"
   ],
   "id": "f4d21ce1b66352fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# simple version by ChatInterface() >> stable\n",
    "#\n",
    "import gradio as gr\n",
    "\n",
    "def chat_response(message, history):\n",
    "    \"\"\"LangChain ì±—ë´‡ ì‘ë‹µ\"\"\"\n",
    "    if not message.strip():\n",
    "        return \"ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "    try:\n",
    "        response = myChain.invoke({\"query\": message})\n",
    "        return response[\"result\"]\n",
    "    except Exception as e:\n",
    "        return f\"âŒ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "# ê°€ì¥ ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_response,\n",
    "    #type=\"messages\",  # only for gradio 4.x\n",
    "    title=\"ğŸ“š ê²½ì œê¸ˆìœµìš©ì–´ ì±—ë´‡\",\n",
    "    examples=[\"GDPë€?\", \"ì¸í”Œë ˆì´ì…˜ì´ë€?\"]\n",
    ")\n",
    "\n",
    "demo.launch()"
   ],
   "id": "2ab3c31520126a2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T06:30:03.120576Z",
     "start_time": "2025-11-17T06:30:03.057590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# simple version by Block()\n",
    "#\n",
    "import gradio as gr\n",
    "\n",
    "# ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±.\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"ğŸ˜ğŸ˜ğŸ¥°ğŸ˜ê²½ì œê¸ˆìœµìš©ì–´ ì±—ë´‡\",\n",
    "        height=300\n",
    "    )\n",
    "    msg = gr.Textbox(\n",
    "        label=\"â‰ï¸ì§ˆë¬¸í•´ì£¼ì„¸ìš”!\",\n",
    "        placeholder=\"ì˜ˆ: GDPë€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "        lines=2\n",
    "    )  # í•˜ë‹¨ì˜ ì±„íŒ…ì°½ì˜ ë ˆì´ë¸”\n",
    "\n",
    "    with gr.Row():\n",
    "        submit = gr.Button(\"âœ…ì „ì†¡\", variant=\"primary\" )\n",
    "        clear = gr.Button(\"â˜‘ï¸ëŒ€í™” ì´ˆê¸°í™”\")  # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼\n",
    "\n",
    "    # ì±—ë´‡ì˜ ë‹µë³€ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
    "    def respond(message, chat_history):\n",
    "        # ì…ë ¥ ê²€ì¦\n",
    "        if not message or not message.strip():\n",
    "            return \"\", chat_history if chat_history else []\n",
    "        # chat_history ì´ˆê¸°í™”\n",
    "        if chat_history is None:\n",
    "            chat_history = []\n",
    "\n",
    "        #bot_message = get_chatbot_response(message)\n",
    "        #reChatChain = myChain.invoke( message )\n",
    "        reChatChain = myChain.invoke({\"query\": message})\n",
    "        bot_message = reChatChain[\"result\"]\n",
    "\n",
    "        # ì±„íŒ… ê¸°ë¡ì— ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì™€ ë´‡ì˜ ì‘ë‹µì„ ì¶”ê°€.\n",
    "        chat_history.append((message, bot_message))\n",
    "        return message, chat_history\n",
    "\n",
    "    def clear_chat():\n",
    "        return []\n",
    "\n",
    "    # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì œì¶œ(submit)í•˜ë©´ respond í•¨ìˆ˜ê°€ í˜¸ì¶œ.\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    submit.click(respond, [msg, chatbot], [msg, chatbot])\n",
    "    # 'ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ì±„íŒ… ê¸°ë¡ì„ ì´ˆê¸°í™”.\n",
    "    clear.click(clear_chat, None, chatbot, queue=False)"
   ],
   "id": "ac76ab4ad87d8c2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰.\n",
    "demo.launch(\n",
    "    debug=True,\n",
    "    inline=True,\n",
    "    share=True,\n",
    ")"
   ],
   "id": "f49422ad1b9dac75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T06:30:06.484163Z",
     "start_time": "2025-11-17T06:30:06.480961Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 63,
   "source": [
    "#\n",
    "# interim test for chating history\n",
    "# chat_histëŠ” ëˆ„ì ëœ ëŒ€í™”ë¥¼ ì§ˆë¬¸ê³¼ ëŒ€ë‹µ 2ê°œì˜ dictionary ì´ë‹¤.\n",
    "#\n",
    "chat_hist = []"
   ],
   "id": "7701d0f1e145f09c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T06:30:15.935672Z",
     "start_time": "2025-11-17T06:30:11.079086Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'dict'>\n",
      "Content: êµ­ë‚´ì´ìƒì‚°(GDP; Gross Domestic Product)ì€ í•œ ë‚˜ë¼ì˜ ì˜ì—­ ë‚´ì—ì„œ ê°€ê³„, ê¸°ì—…, ì •ë¶€ ë“± ëª¨ë“  ê²½ì œ ì£¼ì²´ê°€ ì¼ì • ê¸°ê°„ ë™ì•ˆ ìƒì‚°í™œë™ì— ì°¸ì—¬í•˜ì—¬ ì°½ì¶œí•œ ë¶€ê°€ê°€ì¹˜ ...+++ \n"
     ]
    }
   ],
   "execution_count": 64,
   "source": [
    "test_msg = \"GDPë€?\"\n",
    "result = myChain.invoke({\"query\": test_msg})\n",
    "print(f\"Type: {type(result)}\")\n",
    "#print(f\"Content: {result}\")\n",
    "print(f\"Content: {result['result'][:100]} ...+++ \")"
   ],
   "id": "23c72d0a3257a8fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T06:30:24.843562Z",
     "start_time": "2025-11-17T06:30:20.036281Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New message: GDPë€? <- GDPë€?\n",
      "New history: [('GDPë€?', 'êµ­ë‚´ì´ìƒì‚°(GDP; Gross Domestic Product)ì€ í•œ ë‚˜ë¼ì˜ ì˜ì—­ ë‚´ì—ì„œ ê°€ê³„, ê¸°ì—…, ì •ë¶€ ë“± ëª¨ë“  ê²½ì œ ì£¼ì²´ê°€ ì¼ì • ê¸°ê°„ ë™ì•ˆ ìƒì‚°í™œë™ì— ì°¸ì—¬í•˜ì—¬ ì°½ì¶œí•œ ë¶€ê°€ê°€ì¹˜ ë˜ëŠ” ìµœì¢… ìƒì‚°ë¬¼ì„ ì‹œì¥ê°€ê²©ìœ¼ë¡œ í‰ê°€í•œ í•©ê³„ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” êµ­ë‚´ì— ê±°ì£¼í•˜ëŠ” ë¹„ê±°ì£¼ì(ì™¸êµ­ì¸)ì—ê²Œ ì§€ê¸‰ë˜ëŠ” ì†Œë“ë„ í¬í•¨ë©ë‹ˆë‹¤. \\n\\nGDPëŠ” ê°€ê²©ì˜ ì ìš© ë°©ë²•ì— ë”°ë¼ ëª…ëª© GDP(Nominal GDP)ì™€ ì‹¤ì§ˆ GDP(Real GDP)ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤. ëª…ëª© GDPëŠ” êµ­ê°€ ê²½ì œì˜ ê·œëª¨ë‚˜ êµ¬ì¡° ë“±ì„ íŒŒì•…í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ì‹¤ì§ˆ GDPëŠ” ê²½ì œ ì„±ì¥, ê²½ê¸° ë³€ë™ ë“± ì „ë°˜ì ì¸ ê²½ì œ í™œë™ì˜ íë¦„ì„ ë¶„ì„í•˜ëŠ” ë° ì´ìš©ë©ë‹ˆë‹¤. \\n\\nGDPëŠ” ê²½ì œì˜ ì „ë°˜ì ì¸ ì„±ê³¼ë¥¼ ì¸¡ì •í•˜ëŠ” ì¤‘ìš”í•œ ì§€í‘œë¡œ, êµ­ê°€ì˜ ê²½ì œì  ê±´ê°• ìƒíƒœë¥¼ í‰ê°€í•˜ëŠ” ë° í•„ìˆ˜ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.')]\n"
     ]
    }
   ],
   "execution_count": 65,
   "source": [
    "new_msg, new_hist = respond(test_msg, chat_hist)\n",
    "print(f\"New message: {new_msg} <- {test_msg}\")\n",
    "print(f\"New history: {new_hist}\")"
   ],
   "id": "771e6c36db6582e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T06:30:35.377434Z",
     "start_time": "2025-11-17T06:30:34.026236Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'dict'>\n",
      "Content: ì €ëŠ” Emmaê°€ ê°œë°œí•œ ê¸ˆìœµë„ìš°ë¯¸ì…ë‹ˆë‹¤. ...+++ \n"
     ]
    }
   ],
   "execution_count": 66,
   "source": [
    "test_msg = \"ë„ˆëŠ” ëˆ„ê°€ ê°œë°œí–ˆëŠ”ê°€?\"\n",
    "result = myChain.invoke({\"query\": test_msg})\n",
    "print(f\"Type: {type(result)}\")\n",
    "#print(f\"Content: {result}\")\n",
    "print(f\"Content: {result['result'][:100]} ...+++ \")"
   ],
   "id": "e8710201b783c982"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T06:30:40.069371Z",
     "start_time": "2025-11-17T06:30:38.499071Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New message: ë„ˆëŠ” ëˆ„ê°€ ê°œë°œí–ˆëŠ”ê°€? <- ë„ˆëŠ” ëˆ„ê°€ ê°œë°œí–ˆëŠ”ê°€?\n",
      "New history: [('GDPë€?', 'êµ­ë‚´ì´ìƒì‚°(GDP; Gross Domestic Product)ì€ í•œ ë‚˜ë¼ì˜ ì˜ì—­ ë‚´ì—ì„œ ê°€ê³„, ê¸°ì—…, ì •ë¶€ ë“± ëª¨ë“  ê²½ì œ ì£¼ì²´ê°€ ì¼ì • ê¸°ê°„ ë™ì•ˆ ìƒì‚°í™œë™ì— ì°¸ì—¬í•˜ì—¬ ì°½ì¶œí•œ ë¶€ê°€ê°€ì¹˜ ë˜ëŠ” ìµœì¢… ìƒì‚°ë¬¼ì„ ì‹œì¥ê°€ê²©ìœ¼ë¡œ í‰ê°€í•œ í•©ê³„ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” êµ­ë‚´ì— ê±°ì£¼í•˜ëŠ” ë¹„ê±°ì£¼ì(ì™¸êµ­ì¸)ì—ê²Œ ì§€ê¸‰ë˜ëŠ” ì†Œë“ë„ í¬í•¨ë©ë‹ˆë‹¤. \\n\\nGDPëŠ” ê°€ê²©ì˜ ì ìš© ë°©ë²•ì— ë”°ë¼ ëª…ëª© GDP(Nominal GDP)ì™€ ì‹¤ì§ˆ GDP(Real GDP)ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤. ëª…ëª© GDPëŠ” êµ­ê°€ ê²½ì œì˜ ê·œëª¨ë‚˜ êµ¬ì¡° ë“±ì„ íŒŒì•…í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ì‹¤ì§ˆ GDPëŠ” ê²½ì œ ì„±ì¥, ê²½ê¸° ë³€ë™ ë“± ì „ë°˜ì ì¸ ê²½ì œ í™œë™ì˜ íë¦„ì„ ë¶„ì„í•˜ëŠ” ë° ì´ìš©ë©ë‹ˆë‹¤. \\n\\nGDPëŠ” ê²½ì œì˜ ì „ë°˜ì ì¸ ì„±ê³¼ë¥¼ ì¸¡ì •í•˜ëŠ” ì¤‘ìš”í•œ ì§€í‘œë¡œ, êµ­ê°€ì˜ ê²½ì œì  ê±´ê°• ìƒíƒœë¥¼ í‰ê°€í•˜ëŠ” ë° í•„ìˆ˜ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.'), ('ë„ˆëŠ” ëˆ„ê°€ ê°œë°œí–ˆëŠ”ê°€?', 'ì €ëŠ” Emmaê°€ ê°œë°œí•œ ê¸ˆìœµë„ìš°ë¯¸ì…ë‹ˆë‹¤.')]\n"
     ]
    }
   ],
   "execution_count": 67,
   "source": [
    "new_msg, new_hist = respond(test_msg, chat_hist)\n",
    "print(f\"New message: {new_msg} <- {test_msg}\")\n",
    "print(f\"New history: {new_hist}\")"
   ],
   "id": "9392803478a80a9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
