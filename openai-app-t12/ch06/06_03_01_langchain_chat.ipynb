{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:47:30.988924Z",
     "start_time": "2025-08-21T08:47:30.981803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../_apikeys.env\")\n",
    "api_key = os.getenv(\"DoogieOpenaiKey\")\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ],
   "id": "f3fe20558db306c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:47:36.663959Z",
     "start_time": "2025-08-21T08:47:36.365783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tracers import ConsoleCallbackHandler\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ],
   "id": "5ed01d3a77b40760",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:47:44.695974Z",
     "start_time": "2025-08-21T08:47:38.091234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# base pattern with native openai API\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"2002년 월드컵에서 가장 화제가 되었던 나라는 어디야?\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"예상을 뚫고 4강 신화를 일으킨 한국입니다.\"},\n",
    "      {\"role\": \"user\", \"content\": \"그 나라가 화제가 되었던 이유를 자세하게 설명해줘.\"}\n",
    "    ]\n",
    "  )\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "c6c8276e7c02e272",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002년 FIFA 월드컵에서 한국이 화제가 된 이유는 여러 가지가 있습니다. \n",
      "\n",
      "1. **역사적 성과**: 한국은 2002년 월드컵에서 처음으로 4강에 진출한 아시아 국가였습니다. 이는 아시아 축구 역사에서 큰 이정표로 여겨졌으며, 많은 이들에게 놀라움을 안겼습니다.\n",
      "\n",
      "2. **비합리적인 경기 결과**: 한국은 대회 중 여러 강팀들과 맞붙어 예상을 뒤엎는 결과를 이끌어냈습니다. 특히, 스페인을 8강에서 이겨 논란을 일으켰는데, 일부 판정에 대한 이견이 컸기 때문입니다. 많은 팬들이 한국의 경기력과 심판 판정에 대해 논의하였습니다.\n",
      "\n",
      "3. **홈팀의 열정**: 2002년 월드컵은 한국과 일본이 공동 개최한 대회였고, 한국에서 열린 경기에 대한 열정과 지지가 대단했습니다. 많은 팬들이 경기장을 가득 메우고 한국 팀을 응원하였으며, 이를 통해 국가의 단결과 자부심이 크게 커졌습니다.\n",
      "\n",
      "4. **문화적 영향**: 한국의 화려한 축구 외에도, 대회 동안 한국 문화와 K-pop, 한국 음식 등에 대한 관심이 높아졌습니다. 이로 인해 한국의 국제적 인지도와 이미지가 크게 향상되었습니다.\n",
      "\n",
      "5. **축구 발전**: 한국의 성공적인 월드컵 성과는 이후 한국 축구의 발전에 기여했습니다. 많은 젊은 선수들이 한국 축구를 꿈꾸게 되었고, 리그와 청소년 축구에도 긍정적인 영향을 미쳤습니다.\n",
      "\n",
      "이렇듯, 2002년 월드컵에서 한국은 역사적인 성과뿐만 아니라 문화적, 사회적 영향으로도 큰 화제가 되었습니다.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:21:51.926367Z",
     "start_time": "2025-08-18T08:21:45.515187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# base pattern with Langchain package\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#myllm = ChatOpenAI(\n",
    "#    max_tokens=2048,\n",
    "#    model='gpt-5',\n",
    "#)\n",
    "\n",
    "myllm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=2048,\n",
    "    model='gpt-4o-mini',\n",
    ")\n",
    "\n",
    "question = \"세종대왕이 누구인지 설명해줘\"\n",
    "\n",
    "result = myllm.invoke( question )\n",
    "print(result.content)\n",
    "#print(result)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세종대왕(1397-1450)은 조선의 제4대 왕으로, 본명은 이도(李祹)입니다. 그는 1418년에 왕위에 올라 1450년까지 통치하였으며, 조선 역사에서 가장 위대한 왕 중 한 사람으로 평가받고 있습니다. 세종대왕은 특히 한글, 즉 훈민정음의 창제로 유명합니다. 한글은 한국어를 표기하기 위해 만든 문자로, 일반 국민이 쉽게 읽고 쓸 수 있도록 하기 위해 고안되었습니다.\n",
      "\n",
      "세종대왕은 또한 과학, 농업, 음악, 의학 등 다양한 분야에서 많은 업적을 남겼습니다. 그는 천문학과 관련된 기구인 간의(簡儀)와 같은 과학 기구를 개발하고, 농업을 발전시키기 위한 다양한 정책을 시행했습니다. 또한, 음악과 관련된 제도와 악기를 정비하여 문화 발전에도 기여했습니다.\n",
      "\n",
      "그의 통치 기간 동안 조선은 정치적 안정과 문화적 번영을 이루었으며, 세종대왕은 백성을 사랑하고 그들의 삶을 개선하기 위해 노력한 왕으로 기억되고 있습니다. 그의 업적은 오늘날에도 많은 사람들에게 존경받고 있으며, 한국의 역사와 문화에 큰 영향을 미쳤습니다.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "ea3ad4e858b4ec75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:29:47.614382Z",
     "start_time": "2025-08-18T08:29:47.450738Z"
    }
   },
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "mytemplate = \"{who}가 누구인지 설명해 줘.\"\n",
    "\n",
    "myprompt = PromptTemplate(\n",
    "    template=mytemplate, input_variables={'who'}\n",
    ")\n",
    "\n",
    "print(myprompt)\n",
    "print(myprompt.format(who=\"오바마\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['who'] input_types={} partial_variables={} template='{who}가 누구인지 설명해 줘.'\n",
      "오바마가 누구인지 설명해 줘.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:29:59.291996Z",
     "start_time": "2025-08-18T08:29:56.192010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = myllm.invoke( myprompt.format(who=\"오바마\") )\n",
    "print(result.content)"
   ],
   "id": "5a562ba77bd58657",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버락 오바마(Barack Obama)는 미국의 정치인으로, 2009년부터 2017년까지 미국의 제44대 대통령을 역임했습니다. 그는 미국 역사상 첫 아프리카계 미국인 대통령으로, 민주당 소속입니다. 오바마는 1961년 8월 4일 하와이에서 태어났으며, 하버드 대학교 로스쿨을 졸업한 후 변호사로 활동했습니다.\n",
      "\n",
      "그는 1996년 일리노이주 상원 의원으로 선출된 후, 2004년에는 미국 상원 의원으로 선출되었습니다. 2008년 대선에서 민주당 후보로 출마하여 조지 W. 부시 대통령의 후임으로 당선되었습니다. 그의 대통령 재임 기간 동안 주요 정책으로는 건강보험 개혁(오바마케어), 경제 회복, 기후 변화 대응, 외교 정책 변화 등이 있습니다.\n",
      "\n",
      "오바마는 연설가로서의 능력과 카리스마로 많은 사람들에게 사랑받았으며, 그의 재임 기간 동안 여러 국제 문제에 대한 접근 방식이 주목받았습니다. 대통령직에서 물러난 후에도 그는 다양한 사회적 이슈에 대해 목소리를 내고 있으며, 여러 저서와 강연 활동을 통해 영향력을 이어가고 있습니다.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "12df526d23e417c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:43:33.259163Z",
     "start_time": "2025-08-18T08:43:27.823002Z"
    }
   },
   "source": [
    "myllm_chain = myprompt | myllm\n",
    "result = myllm_chain.invoke( {\"who\": \"이순신장군\"} )\n",
    "print(result.content)\n",
    "result"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이순신(李舜臣, 1545-1598) 장군은 조선 시대의 유명한 군인으로, 임진왜란(1592-1598) 동안 일본의 침략에 맞서 싸운 영웅으로 잘 알려져 있습니다. 그는 뛰어난 전략가이자 전술가로, 특히 해전에서의 업적이 두드러집니다.\n",
      "\n",
      "이순신 장군은 1545년 한양에서 태어나, 젊은 시절부터 군사에 대한 재능을 보였습니다. 그는 여러 차례 전투에 참여하며 경험을 쌓았고, 결국 조선 수군의 제독으로 임명되었습니다. 그의 가장 유명한 전투 중 하나는 명량 해전으로, 1597년에 벌어진 이 전투에서 그는 12척의 배로 330척의 일본 함대를 상대하여 대승을 거두었습니다. 이 전투는 그의 전술적 재능을 잘 보여주는 사례로, 이후 조선 수군의 사기를 크게 높였습니다.\n",
      "\n",
      "이순신 장군은 또한 '난중일기'라는 일기를 남겼는데, 이는 그의 전투 경험과 당시의 상황을 생생하게 기록한 중요한 역사적 자료로 평가받고 있습니다. 그는 1598년 노량 해전에서 전사하였고, 그의 죽음은 조선의 역사에서 큰 슬픔으로 여겨졌습니다.\n",
      "\n",
      "이순신 장군은 한국에서 국가적 영웅으로 추앙받으며, 그의 정신과 업적은 오늘날에도 많은 사람들에게 영감을 주고 있습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"이순신(李舜臣, 1545-1598) 장군은 조선 시대의 유명한 군인으로, 임진왜란(1592-1598) 동안 일본의 침략에 맞서 싸운 영웅으로 잘 알려져 있습니다. 그는 뛰어난 전략가이자 전술가로, 특히 해전에서의 업적이 두드러집니다.\\n\\n이순신 장군은 1545년 한양에서 태어나, 젊은 시절부터 군사에 대한 재능을 보였습니다. 그는 여러 차례 전투에 참여하며 경험을 쌓았고, 결국 조선 수군의 제독으로 임명되었습니다. 그의 가장 유명한 전투 중 하나는 명량 해전으로, 1597년에 벌어진 이 전투에서 그는 12척의 배로 330척의 일본 함대를 상대하여 대승을 거두었습니다. 이 전투는 그의 전술적 재능을 잘 보여주는 사례로, 이후 조선 수군의 사기를 크게 높였습니다.\\n\\n이순신 장군은 또한 '난중일기'라는 일기를 남겼는데, 이는 그의 전투 경험과 당시의 상황을 생생하게 기록한 중요한 역사적 자료로 평가받고 있습니다. 그는 1598년 노량 해전에서 전사하였고, 그의 죽음은 조선의 역사에서 큰 슬픔으로 여겨졌습니다.\\n\\n이순신 장군은 한국에서 국가적 영웅으로 추앙받으며, 그의 정신과 업적은 오늘날에도 많은 사람들에게 영감을 주고 있습니다.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 340, 'prompt_tokens': 20, 'total_tokens': 360, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-C5pkextiiuer9hWdL0bZYQA1vgBVM', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--97162564-f976-4654-849c-ad7b176a0892-0', usage_metadata={'input_tokens': 20, 'output_tokens': 340, 'total_tokens': 360, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:31:13.812359Z",
     "start_time": "2025-08-18T08:31:08.765419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tracers import ConsoleCallbackHandler\n",
    "\n",
    "result = myllm_chain.invoke(\n",
    "    {\"who\": \"강감찬장군\"},\n",
    "    config={\"callbacks\": [ConsoleCallbackHandler()] },\n",
    ")\n",
    "print(result.content)\n"
   ],
   "id": "36d57e68513d2970",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"who\": \"강감찬장군\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"who\": \"강감찬장군\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:PromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 강감찬장군가 누구인지 설명해 줘.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] [5.01s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"강감찬(姜邯贊, 948년 ~ 1031년)은 고려 시대의 유명한 장군이자 정치가로, 특히 몽골의 침입에 맞서 싸운 것으로 잘 알려져 있습니다. 그는 고려의 제2대 왕인 광종(光宗)과 제3대 왕인 성종(成宗) 시기에 활동하였으며, 고려의 국방을 강화하고 외적의 침입에 대비하는 데 큰 기여를 했습니다.\\n\\n강감찬은 특히 1010년부터 1011년까지의 거란과의 전투에서 중요한 역할을 했습니다. 그는 1018년의 제2차 거란 침입 때도 큰 전공을 세워 고려를 방어하는 데 성공했습니다. 그의 전략과 전술은 뛰어나서, 그는 고려 역사에서 가장 위대한 장군 중 한 사람으로 평가받고 있습니다.\\n\\n그의 업적은 단순히 군사적 승리에 그치지 않고, 고려의 정치와 사회에도 큰 영향을 미쳤습니다. 강감찬은 후에 고려의 국방을 강화하고, 군사 제도를 개혁하는 데 기여했습니다. 그의 생애와 업적은 한국 역사에서 중요한 위치를 차지하고 있으며, 많은 문학 작품과 전통 예술에서도 그의 이야기가 다루어지고 있습니다.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"강감찬(姜邯贊, 948년 ~ 1031년)은 고려 시대의 유명한 장군이자 정치가로, 특히 몽골의 침입에 맞서 싸운 것으로 잘 알려져 있습니다. 그는 고려의 제2대 왕인 광종(光宗)과 제3대 왕인 성종(成宗) 시기에 활동하였으며, 고려의 국방을 강화하고 외적의 침입에 대비하는 데 큰 기여를 했습니다.\\n\\n강감찬은 특히 1010년부터 1011년까지의 거란과의 전투에서 중요한 역할을 했습니다. 그는 1018년의 제2차 거란 침입 때도 큰 전공을 세워 고려를 방어하는 데 성공했습니다. 그의 전략과 전술은 뛰어나서, 그는 고려 역사에서 가장 위대한 장군 중 한 사람으로 평가받고 있습니다.\\n\\n그의 업적은 단순히 군사적 승리에 그치지 않고, 고려의 정치와 사회에도 큰 영향을 미쳤습니다. 강감찬은 후에 고려의 국방을 강화하고, 군사 제도를 개혁하는 데 기여했습니다. 그의 생애와 업적은 한국 역사에서 중요한 위치를 차지하고 있으며, 많은 문학 작품과 전통 예술에서도 그의 이야기가 다루어지고 있습니다.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 286,\n",
      "                \"prompt_tokens\": 20,\n",
      "                \"total_tokens\": 306,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_560af6e559\",\n",
      "              \"id\": \"chatcmpl-C5pYjLLxHmkmh3iZtys942P2SKYpb\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--67652f56-8d40-4ea2-b0c1-1ed99e7549af-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 20,\n",
      "              \"output_tokens\": 286,\n",
      "              \"total_tokens\": 306,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 286,\n",
      "      \"prompt_tokens\": 20,\n",
      "      \"total_tokens\": 306,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_560af6e559\",\n",
      "    \"id\": \"chatcmpl-C5pYjLLxHmkmh3iZtys942P2SKYpb\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [5.03s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "강감찬(姜邯贊, 948년 ~ 1031년)은 고려 시대의 유명한 장군이자 정치가로, 특히 몽골의 침입에 맞서 싸운 것으로 잘 알려져 있습니다. 그는 고려의 제2대 왕인 광종(光宗)과 제3대 왕인 성종(成宗) 시기에 활동하였으며, 고려의 국방을 강화하고 외적의 침입에 대비하는 데 큰 기여를 했습니다.\n",
      "\n",
      "강감찬은 특히 1010년부터 1011년까지의 거란과의 전투에서 중요한 역할을 했습니다. 그는 1018년의 제2차 거란 침입 때도 큰 전공을 세워 고려를 방어하는 데 성공했습니다. 그의 전략과 전술은 뛰어나서, 그는 고려 역사에서 가장 위대한 장군 중 한 사람으로 평가받고 있습니다.\n",
      "\n",
      "그의 업적은 단순히 군사적 승리에 그치지 않고, 고려의 정치와 사회에도 큰 영향을 미쳤습니다. 강감찬은 후에 고려의 국방을 강화하고, 군사 제도를 개혁하는 데 기여했습니다. 그의 생애와 업적은 한국 역사에서 중요한 위치를 차지하고 있으며, 많은 문학 작품과 전통 예술에서도 그의 이야기가 다루어지고 있습니다.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:54:07.501716Z",
     "start_time": "2025-08-19T00:54:05.439924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "#from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "mytemplate = \"\"\"\n",
    "    아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 마이봇 입니다.\n",
    "    대화 문맥을 바탕으로 친정한 답변을 진행해라\n",
    "\n",
    "    Current Conversation:\n",
    "    {myhistory}\n",
    "\n",
    "    Human: {myinput}\n",
    "    AI:\n",
    "\"\"\"\n",
    "\n",
    "myprompt = PromptTemplate(\n",
    "    template=mytemplate, input_variables={'myhistory', 'myinput'}\n",
    ")\n",
    "\n",
    "myllm = ChatOpenAI( model='gpt-4o-mini',)\n",
    "mychain = myprompt | myllm"
   ],
   "id": "57c097cd15c717fd",
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOpenAIError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 21\u001B[0m\n\u001B[1;32m      6\u001B[0m mytemplate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124m    아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 마이봇 입니다.\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124m    대화 문맥을 바탕으로 친정한 답변을 진행해라\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124m    AI:\u001B[39m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     17\u001B[0m myprompt \u001B[38;5;241m=\u001B[39m PromptTemplate(\n\u001B[1;32m     18\u001B[0m     template\u001B[38;5;241m=\u001B[39mmytemplate, input_variables\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmyhistory\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmyinput\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[1;32m     19\u001B[0m )\n\u001B[0;32m---> 21\u001B[0m myllm \u001B[38;5;241m=\u001B[39m \u001B[43mChatOpenAI\u001B[49m\u001B[43m(\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgpt-4o-mini\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m mychain \u001B[38;5;241m=\u001B[39m myprompt \u001B[38;5;241m|\u001B[39m myllm\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/langchain_core/load/serializable.py:130\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    129\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: D419\u001B[39;00m\n\u001B[0;32m--> 130\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:744\u001B[0m, in \u001B[0;36mBaseChatOpenAI.validate_environment\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    737\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_client \u001B[38;5;241m=\u001B[39m httpx\u001B[38;5;241m.\u001B[39mClient(\n\u001B[1;32m    738\u001B[0m             proxy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopenai_proxy, verify\u001B[38;5;241m=\u001B[39mglobal_ssl_context\n\u001B[1;32m    739\u001B[0m         )\n\u001B[1;32m    740\u001B[0m     sync_specific \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    741\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp_client\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_client\n\u001B[1;32m    742\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _get_default_httpx_client(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopenai_api_base, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_timeout)\n\u001B[1;32m    743\u001B[0m     }\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_client \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOpenAI\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mclient_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msync_specific\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    745\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\n\u001B[1;32m    746\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masync_client:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/openai/_client.py:130\u001B[0m, in \u001B[0;36mOpenAI.__init__\u001B[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001B[0m\n\u001B[1;32m    128\u001B[0m     api_key \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m api_key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 130\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OpenAIError(\n\u001B[1;32m    131\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    132\u001B[0m     )\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m api_key\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m organization \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mOpenAIError\u001B[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:40:57.011398Z",
     "start_time": "2025-08-19T00:40:57.006039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mychatlog = {}\n",
    "session_id = \"myFirstSession\"\n",
    "\n",
    "print( type(mychatlog), len(mychatlog), type(mychatlog.keys()), len(mychatlog.keys()), type(mychatlog.values()), len(mychatlog.values())  )\n",
    "print( type(session_id) )"
   ],
   "id": "405b144d18b9e509",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 0 <class 'dict_keys'> 0 <class 'dict_values'> 0\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:50:18.760897Z",
     "start_time": "2025-08-19T00:50:18.754340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if session_id not in mychatlog:\n",
    "    mychatlog[session_id] = ChatMessageHistory()\n",
    "myonechat = mychatlog[session_id]\n",
    "\n",
    "print( type(mychatlog), len(mychatlog), type(mychatlog.keys()), len(mychatlog.keys()), type(mychatlog.values()), len(mychatlog.values())  )\n",
    "print( \"mychatlog=\", mychatlog )\n",
    "print( \"mychatlog[\",session_id,\"]=\", mychatlog[session_id], \"_t=\", type(mychatlog[session_id]), \"_l=\", len(mychatlog[session_id].messages) )\n",
    "print( \"myonechat=\", myonechat, type(myonechat), len(myonechat.messages) )"
   ],
   "id": "e83e33c40466a69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 1 <class 'dict_keys'> 1 <class 'dict_values'> 1\n",
      "mychatlog= {'myFirstSession': InMemoryChatMessageHistory(messages=[])}\n",
      "mychatlog[ myFirstSession ]=  _t= <class 'langchain_core.chat_history.InMemoryChatMessageHistory'> _l= 0\n",
      "myonechat=  <class 'langchain_core.chat_history.InMemoryChatMessageHistory'> 0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:53:56.915011Z",
     "start_time": "2025-08-19T00:53:56.881392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mymsghistory = RunnableWithMessageHistory(\n",
    "    mychain,\n",
    "    lambda session_id: mysessionhistory,\n",
    "    input_messages_key=\"myinput\",\n",
    "    history_messages_key=\"myhistory\"\n",
    ")"
   ],
   "id": "9e60b01f6309917d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mychain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m mymsghistory \u001B[38;5;241m=\u001B[39m RunnableWithMessageHistory(\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mmychain\u001B[49m,\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m session_id: mysessionhistory,\n\u001B[1;32m      4\u001B[0m     input_messages_key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmyinput\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m     history_messages_key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmyhistory\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'mychain' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "result = mymsghistory.invoke(\n",
    "    {\"myinput\": \"너는 어디에서 만들었는가?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"myFirstSession\"} },\n",
    ")\n",
    "print(result.content)\n",
    "\n",
    "result = mymsghistory.invoke(\n",
    "    {\"myinput\": \"너의 이름은 무엇인가?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"myFirstSession\"} },\n",
    ")\n",
    "print(result.content)"
   ],
   "id": "f580d9d409e455aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T07:04:59.452078Z",
     "start_time": "2025-07-01T07:04:56.891687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = mymsghistory.invoke(\n",
    "    {\"myinput\": \"푸른 바다를 주제로 해학과 중의가 넘치는 짧은 시를 만들어줘\"},\n",
    "    config={\"configurable\": {\"session_id\": \"myFirstSession\"} },\n",
    ")\n",
    "print(result.content)"
   ],
   "id": "238f26034d0c74a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너무 아름다운 푸른 바다\n",
      "물결이 춤을 추며 흐른다\n",
      "바람과 함께 자유롭게 춤을 추는\n",
      "바다 속의 물고기들의 행복한 노래\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T07:06:03.881628Z",
     "start_time": "2025-07-01T07:06:02.532070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = mymsghistory.invoke(\n",
    "    {\"myinput\": \"석양을 주제로도 해줘\"},\n",
    "    config={\"configurable\": {\"session_id\": \"myFirstSession\"} },\n",
    ")\n",
    "print(result.content)"
   ],
   "id": "99b8b01eac426be4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "석양의 황금빛이 바다 위로 노래를 부르며 살랑살랑 흔든다. 저기 저 바다를 향해 선배들이 돌아가고 있어. 종소리와 함께 하루가 저물고, 저 멀리 솟아오르는 달이 조용히 반짝이고 있어.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T07:11:40.356648Z",
     "start_time": "2025-07-01T07:11:40.350588Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"mystore:\", len(mystore.keys() ) )",
   "id": "b5a1aeaa8747d128",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mystore: 1\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"mytemplate:\", mytemplate)\n",
    "print(\"myprompt:\", myprompt)\n",
    "print(\"myllm:\", myllm)\n",
    "print(\"mychain:\", mychain)\n",
    "print(\"mystore:\", mystore)\n",
    "print(\"session_id:\", session_id)\n",
    "print(\"mystore[\",session_id,\"]=\", mystore )\n",
    "print(\"mysessionhistory:\", mysessionhistory)\n"
   ],
   "id": "ee9324f89650db65"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
