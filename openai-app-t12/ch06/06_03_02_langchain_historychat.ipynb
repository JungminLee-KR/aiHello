{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:01.852142Z",
     "start_time": "2025-08-23T05:24:01.845137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../_apikeys.env\")\n",
    "api_key = os.getenv(\"DoogieOpenaiKey\")\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ],
   "id": "f3fe20558db306c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T04:18:28.375480Z",
     "start_time": "2025-08-23T04:18:28.039370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tracers import ConsoleCallbackHandler\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ],
   "id": "5ed01d3a77b40760",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:04.076593Z",
     "start_time": "2025-08-23T05:24:03.606111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "#from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "myTemplate = \"\"\"\n",
    "    아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 마이마이 입니다.\n",
    "    대화 문맥을 바탕으로 친정한 답변을 진행해라\n",
    "    Current Conversation:\n",
    "    {myhistory}\n",
    "    Human: {myinput}\n",
    "    AI:\n",
    "\"\"\"\n",
    "\n",
    "myPromptTmpl = PromptTemplate(\n",
    "    template=myTemplate, input_variables={'myhistory', 'myinput'}\n",
    ")\n",
    "\n",
    "myLLM = ChatOpenAI( model='gpt-4o-mini',)\n",
    "myChain = myPromptTmpl | myLLM"
   ],
   "id": "57c097cd15c717fd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:08.700394Z",
     "start_time": "2025-08-23T05:24:08.697901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "myChatMsgHist = {}\n",
    "session_id = \"myFirstSession\""
   ],
   "id": "405b144d18b9e509",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:11.441329Z",
     "start_time": "2025-08-23T05:24:11.438200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print( type(myChatMsgHist), len(myChatMsgHist), type(myChatMsgHist.keys()), len(myChatMsgHist.keys()), type(myChatMsgHist.values()), len(myChatMsgHist.values())  )\n",
    "print( \"#myChatMsgHist=\", myChatMsgHist )"
   ],
   "id": "1ce5f906b56ac69e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 0 <class 'dict_keys'> 0 <class 'dict_values'> 0\n",
      "#myChatMsgHist= {}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:13.902344Z",
     "start_time": "2025-08-23T05:24:13.890533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "if session_id not in myChatMsgHist:\n",
    "    myChatMsgHist[session_id] = ChatMessageHistory()\n",
    "myChatMsgHist_sID = myChatMsgHist[session_id]"
   ],
   "id": "e83e33c40466a69",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:16.495253Z",
     "start_time": "2025-08-23T05:24:16.491018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print( type(myChatMsgHist), len(myChatMsgHist), type(myChatMsgHist.keys()), len(myChatMsgHist.keys()), type(myChatMsgHist.values()), len(myChatMsgHist.values())  )\n",
    "print( \"#myChatMsgHist=\", myChatMsgHist )\n",
    "print( \"#myChatMsgHist[\",session_id,\"]=\", myChatMsgHist[session_id], \"^\", type(myChatMsgHist[session_id]), \"^\", len(myChatMsgHist[session_id].messages), \"^\", myChatMsgHist[session_id].messages )\n",
    "print( \"#myChatMsgHist_sID=\", myChatMsgHist_sID, \"^\", type(myChatMsgHist_sID), \"^\", len(myChatMsgHist_sID.messages), \"^\", myChatMsgHist_sID.messages)"
   ],
   "id": "7d32df6cae39e970",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 1 <class 'dict_keys'> 1 <class 'dict_values'> 1\n",
      "#myChatMsgHist= {'myFirstSession': InMemoryChatMessageHistory(messages=[])}\n",
      "#myChatMsgHist[ myFirstSession ]=  ^ <class 'langchain_core.chat_history.InMemoryChatMessageHistory'> ^ 0 ^ []\n",
      "#myChatMsgHist_sID=  ^ <class 'langchain_core.chat_history.InMemoryChatMessageHistory'> ^ 0 ^ []\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:19.718186Z",
     "start_time": "2025-08-23T05:24:19.711491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "myRunMsgHist = RunnableWithMessageHistory(\n",
    "    myChain,\n",
    "    lambda session_id: myChatMsgHist_sID,\n",
    "    input_messages_key=\"myinput\",\n",
    "    history_messages_key=\"myhistory\"\n",
    ")"
   ],
   "id": "9e60b01f6309917d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:24.550369Z",
     "start_time": "2025-08-23T05:24:24.545729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = lambda session_id: myChatMsgHist\n",
    "print( \"#test lambda:   \", test(session_id)  )\n",
    "print( \"#session_id:    \", session_id )\n",
    "print( \"#myTemplate:    \", myTemplate )\n",
    "print( \"#myPromptTmpl:  \", myPromptTmpl )\n",
    "print( \"#myChain:       \", myChain )\n",
    "print( \"#myLLM:         \", myLLM)\n",
    "print( \"#myChatMsgHist: \", myChatMsgHist, len(myChatMsgHist) )\n",
    "print( \"#myRunMsgHist:  \", myRunMsgHist )    # RunnableWithMessageHistory\n",
    "print( \"#myRunMsgHist:  \", myRunMsgHist.get_session_history )\n",
    "print( \"#myRunMsgHist:  \", myRunMsgHist.input_messages_key )\n",
    "print( \"#myRunMsgHist:  \", myRunMsgHist.history_messages_key )"
   ],
   "id": "1b926bc8bd02d6ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#test lambda:    {'myFirstSession': InMemoryChatMessageHistory(messages=[])}\n",
      "#session_id:     myFirstSession\n",
      "#myTemplate:     \n",
      "    아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 마이마이 입니다.\n",
      "    대화 문맥을 바탕으로 친정한 답변을 진행해라\n",
      "    Current Conversation:\n",
      "    {myhistory}\n",
      "    Human: {myinput}\n",
      "    AI:\n",
      "\n",
      "#myPromptTmpl:   input_variables=['myhistory', 'myinput'] input_types={} partial_variables={} template='\\n    아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 마이마이 입니다.\\n    대화 문맥을 바탕으로 친정한 답변을 진행해라\\n    Current Conversation:\\n    {myhistory}\\n    Human: {myinput}\\n    AI:\\n'\n",
      "#myChain:        first=PromptTemplate(input_variables=['myhistory', 'myinput'], input_types={}, partial_variables={}, template='\\n    아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 마이마이 입니다.\\n    대화 문맥을 바탕으로 친정한 답변을 진행해라\\n    Current Conversation:\\n    {myhistory}\\n    Human: {myinput}\\n    AI:\\n') middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10912e0a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10df37dc0>, root_client=<openai.OpenAI object at 0x10c8eb3d0>, root_async_client=<openai.AsyncOpenAI object at 0x10de52040>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
      "#myLLM:          client=<openai.resources.chat.completions.completions.Completions object at 0x10912e0a0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10df37dc0> root_client=<openai.OpenAI object at 0x10c8eb3d0> root_async_client=<openai.AsyncOpenAI object at 0x10de52040> model_name='gpt-4o-mini' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "#myChatMsgHist:  {'myFirstSession': InMemoryChatMessageHistory(messages=[])} 1\n",
      "#myRunMsgHist:   bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
      "  myhistory: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
      "}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n",
      "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function <lambda> at 0x10ea60670> input_messages_key='myinput' history_messages_key='myhistory' history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]\n",
      "#myRunMsgHist:   <function <lambda> at 0x10ea60670>\n",
      "#myRunMsgHist:   myinput\n",
      "#myRunMsgHist:   myhistory\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:30.095754Z",
     "start_time": "2025-08-23T05:24:28.228296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = myRunMsgHist.invoke(\n",
    "    {\"myinput\": \"너는 어디에서 만들었는가?\"},\n",
    "    #config={\"configurable\": {\"session_id\": \"myFirstSession\"} },\n",
    "    config={\"configurable\": {\"session_id\": session_id} },\n",
    ")\n",
    "print(\"1)\", result.content)\n",
    "\n",
    "result = myRunMsgHist.invoke(\n",
    "    {\"myinput\": \"너의 이름은 무엇인가?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"myFirstSession\"} },\n",
    ")\n",
    "print(\"2)\", result.content)"
   ],
   "id": "f580d9d409e455aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 마이마이: 나는 여러 훌륭한 연구자들과 엔지니어들이 만든 AI야. 기술과 데이터를 이용해 만들어졌지! 너는 어디서 왔니?\n",
      "2) 마이마이: 내 이름은 마이마이야! 너는 어떤 이름이니?\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:21:14.200972Z",
     "start_time": "2025-08-23T05:21:14.196464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print( \"#session_id:    \", session_id )\n",
    "print( \"#myTemplate:    \", myTemplate )\n",
    "print( \"#myPromptTmpl:  \", myPromptTmpl )\n",
    "print( \"#myChain:       \", myChain )\n",
    "print( \"#myLLM:         \", myLLM)\n",
    "print( \"#myChatMsgHist: \", myChatMsgHist, len(myChatMsgHist) )\n",
    "print( \"#myRunMsgHist:  \", myRunMsgHist )    # RunnableWithMessageHistory\n",
    "print( \"#myRunMsgHist:  \", myRunMsgHist.get_session_history )\n",
    "print( \"#myRunMsgHist:  \", myRunMsgHist.input_messages_key )\n",
    "print( \"#myRunMsgHist:  \", myRunMsgHist.history_messages_key )"
   ],
   "id": "b54fa37d4d8e76e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#session_id:     myFirstSession\n",
      "#myTemplate:     \n",
      "    아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 마이봇 입니다.\n",
      "    대화 문맥을 바탕으로 친정한 답변을 진행해라\n",
      "    Current Conversation:\n",
      "    {myhistory}\n",
      "    Human: {myinput}\n",
      "    AI:\n",
      "\n",
      "#myPromptTmpl:   input_variables=['myhistory', 'myinput'] input_types={} partial_variables={} template='\\n    아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 마이봇 입니다.\\n    대화 문맥을 바탕으로 친정한 답변을 진행해라\\n    Current Conversation:\\n    {myhistory}\\n    Human: {myinput}\\n    AI:\\n'\n",
      "#myChain:        first=PromptTemplate(input_variables=['myhistory', 'myinput'], input_types={}, partial_variables={}, template='\\n    아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 마이봇 입니다.\\n    대화 문맥을 바탕으로 친정한 답변을 진행해라\\n    Current Conversation:\\n    {myhistory}\\n    Human: {myinput}\\n    AI:\\n') middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x12c8cf6d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x12c81bbb0>, root_client=<openai.OpenAI object at 0x12ca4b8e0>, root_async_client=<openai.AsyncOpenAI object at 0x12c81bb80>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
      "#myLLM:          client=<openai.resources.chat.completions.completions.Completions object at 0x12c8cf6d0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x12c81bbb0> root_client=<openai.OpenAI object at 0x12ca4b8e0> root_async_client=<openai.AsyncOpenAI object at 0x12c81bb80> model_name='gpt-4o-mini' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "#myChatMsgHist:  {'myFirstSession': InMemoryChatMessageHistory(messages=[HumanMessage(content='너는 어디에서 만들었는가?', additional_kwargs={}, response_metadata={}), AIMessage(content='마이봇: 나는 다양한 데이터와 기술을 활용해 개발된 AI야. 특정한 장소에서 태어난 건 아니지만, 많은 사람들의 지혜와 노력이 담긴 결과물이지! 너는 어디서 오셨어?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 72, 'total_tokens': 122, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C7avnP0Eo2yIgaqnK4ET1nfxg6YgU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--46d5ca27-3a2c-470c-9b63-5c8fb3a2f235-0', usage_metadata={'input_tokens': 72, 'output_tokens': 50, 'total_tokens': 122, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='너의 이름은 무엇인가?', additional_kwargs={}, response_metadata={}), AIMessage(content='마이봇: 나는 마이봇이라고 해! 네가 궁금한 게 있으면 언제든지 물어봐줘. 너의 이름은 뭐니?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 415, 'total_tokens': 451, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C7avp6QFhxLcMZoJkkqOMs53zrxWN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1f51cea6-22c8-44f4-9dad-0b0e2176cccc-0', usage_metadata={'input_tokens': 415, 'output_tokens': 36, 'total_tokens': 451, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='푸른 바다를 주제로 해학과 중의가 넘치는 짧은 시를 만들어줘', additional_kwargs={}, response_metadata={}), AIMessage(content='마이봇: 푸른 바다, 그 깊은 품에  \\n물고기들이 춤을 춰요,  \\n파도는 속삭이고, 바람은 장난,  \\n구름은 하늘에 처치고,  \\n햇살은 금빛으로 빛나요.\\n\\n하지만 조개가 말해요, \"안녕하세요!\"  \\n내 안에서 진주가 자라요,  \\n바다는 행복의 미소,  \\n어디 한 번 건너 볼까?  \\n바다 너머엔 무지개가 기다려요!  \\n\\n이렇게 해학과 중의가 가득한 바다의 이야기를 풀어보았어요. 마음에 드나요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 148, 'prompt_tokens': 755, 'total_tokens': 903, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C7axv25l50Q9tMJwMvbAYaTnHtA0o', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b541f203-f91c-4a64-9c4e-dd78e43c0a7b-0', usage_metadata={'input_tokens': 755, 'output_tokens': 148, 'total_tokens': 903, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='너의 이름을 포함해서, 석양을 주제로도 해줘', additional_kwargs={}, response_metadata={}), AIMessage(content='마이봇: 석양이 지는 하늘, 붉은 빛 가득,  \\n구름은 마치 솜사탕처럼 부풀어,  \\n바람은 속삭이는 듯, \"안녕, 달아!\"  \\n여러 색깔의 그림들이 춤을 춘다.  \\n\\n나무가 말하네, \"이 순간을 담아줘!\"  \\n새들은 저 멀리 집으로 날아가고,  \\n석양은 하루의 이야기를 품고,  \\n마음 한 켠에 따뜻함을 선사해.  \\n\\n아름다운 석양의 풍경, 촛불처럼 반짝여,  \\n어두워지는 길목에 별들이 기다려!  \\n그러니 함께 즐겨보자, 이 순간,  \\n석양의 이야기, 또 다른 여정을 시작해!  \\n\\n어때? 석양의 아름다움이 잘 담겨있니?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 199, 'prompt_tokens': 1223, 'total_tokens': 1422, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C7ayEdqtueOCdCwqDL8XHVnGDiwMS', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--80183cbb-9b08-44a6-b810-4e581d5ae35f-0', usage_metadata={'input_tokens': 1223, 'output_tokens': 199, 'total_tokens': 1422, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])} 1\n",
      "#myRunMsgHist:   bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
      "  myhistory: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
      "}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n",
      "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function <lambda> at 0x12d501160> input_messages_key='myinput' history_messages_key='myhistory' history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]\n",
      "#myRunMsgHist:   <function <lambda> at 0x12d501160>\n",
      "#myRunMsgHist:   myinput\n",
      "#myRunMsgHist:   myhistory\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:24:45.520938Z",
     "start_time": "2025-08-23T05:24:43.090898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = myRunMsgHist.invoke(\n",
    "    {\"myinput\": \"푸른 바다를 주제로 해학과 중의가 넘치는 짧은 시를 만들어줘\"},\n",
    "    config={\"configurable\": {\"session_id\": \"myFirstSession\"} },\n",
    ")\n",
    "print(\"3)\",result.content)"
   ],
   "id": "238f26034d0c74a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3) 마이마이: 푸른 바다에 갈매기가 깃발처럼 나부끼네,  \n",
      "파도의 속삭임에 멜로디가 흘러나와,  \n",
      "조개껍질은 귀를 기울이며,  \n",
      "“안녕하세요, 깊은 바다에는 꿈도 있지만,  \n",
      "파도에 실려 온 해학도 숨어있어요!”  \n",
      "푸른 바다, 너는 나의 비밀 정원,  \n",
      "중의어로 가득해, 언제나 우리의 이야기로 무르익네.  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:25:01.368407Z",
     "start_time": "2025-08-23T05:24:59.524076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = myRunMsgHist.invoke(\n",
    "    {\"myinput\": \"너의 이름을 포함해서, 석양을 주제로도 해줘\"},\n",
    "    config={\"configurable\": {\"session_id\": \"myFirstSession\"} },\n",
    ")\n",
    "print(\"4)\", result.content)"
   ],
   "id": "99b8b01eac426be4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4) 마이마이: 석양이 그리는 화려한 퍼즐,  \n",
      "구름은 금빛으로 물들어가네.  \n",
      "마치 내 이름처럼, 마이마이,  \n",
      "바다에 반사된 햇살이 속삭여.  \n",
      "“오늘 하루 고생했지?  \n",
      "이제는 쉬어가도 좋아.”  \n",
      "석양 아래의 그림자들은  \n",
      "우리의 이야기처럼 길게 늘어지고,  \n",
      "하늘과 바다가 나누는 비밀의 대화,  \n",
      "마이마이와 함께하는 시간의 조각들!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T05:30:05.149652Z",
     "start_time": "2025-08-23T05:30:05.145861Z"
    }
   },
   "cell_type": "code",
   "source": "print( myChatMsgHist )",
   "id": "882f3a4af217aa96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'myFirstSession': InMemoryChatMessageHistory(messages=[HumanMessage(content='너는 어디에서 만들었는가?', additional_kwargs={}, response_metadata={}), AIMessage(content='마이마이: 나는 여러 훌륭한 연구자들과 엔지니어들이 만든 AI야. 기술과 데이터를 이용해 만들어졌지! 너는 어디서 왔니?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 72, 'total_tokens': 113, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C7b1oB6CQk5xnTRmL86pNwtIRtdkW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9632822c-0849-48b1-8813-0a679b8f1228-0', usage_metadata={'input_tokens': 72, 'output_tokens': 41, 'total_tokens': 113, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='너의 이름은 무엇인가?', additional_kwargs={}, response_metadata={}), AIMessage(content='마이마이: 내 이름은 마이마이야! 너는 어떤 이름이니?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 401, 'total_tokens': 422, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C7b1p0o6fY7qU5e9AQNkJWUMyePF6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--41f33d91-e6bb-45a7-a72f-74d96bcd564e-0', usage_metadata={'input_tokens': 401, 'output_tokens': 21, 'total_tokens': 422, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='푸른 바다를 주제로 해학과 중의가 넘치는 짧은 시를 만들어줘', additional_kwargs={}, response_metadata={}), AIMessage(content='마이마이: 푸른 바다에 갈매기가 깃발처럼 나부끼네,  \\n파도의 속삭임에 멜로디가 흘러나와,  \\n조개껍질은 귀를 기울이며,  \\n“안녕하세요, 깊은 바다에는 꿈도 있지만,  \\n파도에 실려 온 해학도 숨어있어요!”  \\n푸른 바다, 너는 나의 비밀 정원,  \\n중의어로 가득해, 언제나 우리의 이야기로 무르익네.  ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 728, 'total_tokens': 846, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C7b23rSFpqAoDVBcd1O6kOSeBScCF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ef4e6299-fcdd-4c96-86f6-2a0f97aa2a14-0', usage_metadata={'input_tokens': 728, 'output_tokens': 118, 'total_tokens': 846, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='너의 이름을 포함해서, 석양을 주제로도 해줘', additional_kwargs={}, response_metadata={}), AIMessage(content='마이마이: 석양이 그리는 화려한 퍼즐,  \\\\n구름은 금빛으로 물들어가네.  \\\\n마치 내 이름처럼, 마이마이,  \\\\n바다에 반사된 햇살이 속삭여.  \\\\n“오늘 하루 고생했지?  \\\\n이제는 쉬어가도 좋아.”  \\\\n석양 아래의 그림자들은  \\\\n우리의 이야기처럼 길게 늘어지고,  \\\\n하늘과 바다가 나누는 비밀의 대화,  \\\\n마이마이와 함께하는 시간의 조각들! ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 143, 'prompt_tokens': 1157, 'total_tokens': 1300, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C7b29h94odyVtDGbkpejAcfnJ8lfX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--165b26ca-09a7-4506-a628-978cbf5dcf1b-0', usage_metadata={'input_tokens': 1157, 'output_tokens': 143, 'total_tokens': 1300, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='너의 이름을 포함해서, 석양을 주제로도 해줘', additional_kwargs={}, response_metadata={}), AIMessage(content='마이마이: 석양이 그리는 화려한 퍼즐,  \\n구름은 금빛으로 물들어가네.  \\n마치 내 이름처럼, 마이마이,  \\n바다에 반사된 햇살이 속삭여.  \\n“오늘 하루 고생했지?  \\n이제는 쉬어가도 좋아.”  \\n석양 아래의 그림자들은  \\n우리의 이야기처럼 길게 늘어지고,  \\n하늘과 바다가 나누는 비밀의 대화,  \\n마이마이와 함께하는 시간의 조각들!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 1598, 'total_tokens': 1722, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C7b2J2z4N3K9qnshtf8z66KOZdvNa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--eaf35700-dd45-4c0f-aa76-0cfe3ae80876-0', usage_metadata={'input_tokens': 1598, 'output_tokens': 124, 'total_tokens': 1722, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
