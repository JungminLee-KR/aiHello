{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-10T04:05:02.631081Z",
     "start_time": "2025-11-10T04:05:02.612693Z"
    }
   },
   "source": [
    "import os, sys, shutil\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../_apikeys.env\")\n",
    "api_key = os.getenv(\"DoogieOpenaiKey\")\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 1-1: get test documents\n",
    "#\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/chatgpt-kr/openai-api-tutorial/raw/main/ch06/2023_%EB%B6%81%ED%95%9C%EC%9D%B8%EA%B6%8C%EB%B3%B4%EA%B3%A0%EC%84%9C.pdf\", filename=\"06_07_test.pdf\")"
   ],
   "id": "7dbde76dc7a2f13c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:05:22.796309Z",
     "start_time": "2025-11-10T04:05:07.097833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 1-2: load and split documents\n",
    "# 17~20 sec\n",
    "#\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader( \"06_07_test.pdf\" )\n",
    "pages = loader.load_and_split()  # about 17s\n",
    "#pages = loader.load()  # about 16s, include empty page\n"
   ],
   "id": "97349a1e9c9a70cd",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:05:25.069805Z",
     "start_time": "2025-11-10T04:05:25.060567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print( 'type loader,pages:', type(loader), type(pages) )\n",
    "print( 'type pages[0]s:', type(pages[0]), type(pages[0].page_content))\n",
    "print( 'size/len loader,pages:', sys.getsizeof(loader), len(pages) )\n",
    "print( 'size/len pages[0]s:', sys.getsizeof(pages[0]), len(pages[0].page_content) )\n",
    "print( 'pages Max:', max(len(apage.page_content) for apage in pages ) )\n",
    "print( 'pages Min:', min(len(apage.page_content) for apage in pages ) )\n",
    "print( 'pages Sum:', sum(len(apage.page_content) for apage in pages ) )\n",
    "print( '#of chunks:', len(pages) )\n",
    "print( 'Chunk Avg:', sum(len(apage.page_content) for apage in pages ) / len(pages) )"
   ],
   "id": "4642e6abb2a5cd14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type loader,pages: <class 'langchain_community.document_loaders.pdf.PyPDFLoader'> <class 'list'>\n",
      "type pages[0]s: <class 'langchain_core.documents.base.Document'> <class 'str'>\n",
      "size/len loader,pages: 48 445\n",
      "size/len pages[0]s: 72 57\n",
      "pages Max: 1640\n",
      "pages Min: 6\n",
      "pages Sum: 372229\n",
      "#of chunks: 445\n",
      "Chunk Avg: 836.4696629213483\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#print( pages[0] )\n",
    "#print( pages[0].page_content)\n",
    "#print( \"example:\", pages[6].page_content[:50] )\n",
    "#print( pages[442].page_content )"
   ],
   "id": "95f7bb8ba1bcbccd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:05:30.511932Z",
     "start_time": "2025-11-10T04:05:30.318149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: case1:\n",
    "# RecursiveCharacterTextSpilter를 사용함\n",
    "#\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "textSplitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size= 1000,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "splitedDocs = textSplitter.split_documents( pages )"
   ],
   "id": "3d2bc0cdf6ef0133",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:05:32.533708Z",
     "start_time": "2025-11-10T04:05:32.524104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print( 'type split,splitDocs:', type(textSplitter), type(splitedDocs) )\n",
    "print( 'type splitedDocs[0]s:', type(splitedDocs[0]), type(splitedDocs[0].page_content) )\n",
    "print( 'size/len split,splitDocs:', sys.getsizeof(textSplitter), len(splitedDocs) )\n",
    "print( 'size/len splitedDocs[0]s:', sys.getsizeof(splitedDocs[0]), len(splitedDocs[0].page_content) )\n",
    "print( 'splitedDocs Max:', max(len(apage.page_content) for apage in splitedDocs ) )\n",
    "print( 'splitedDocs Min:', min(len(apage.page_content) for apage in splitedDocs ) )\n",
    "print( 'splitedDocs Sum:', sum(len(apage.page_content) for apage in splitedDocs ) )\n",
    "print( '#of chunks:', len(splitedDocs) )\n",
    "print( 'Chunk Avg:', sum(len(apage.page_content) for apage in splitedDocs ) / len(splitedDocs) )"
   ],
   "id": "aecff3c27907fced",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type split,splitDocs: <class 'langchain_text_splitters.character.RecursiveCharacterTextSplitter'> <class 'list'>\n",
      "type splitedDocs[0]s: <class 'langchain_core.documents.base.Document'> <class 'str'>\n",
      "size/len split,splitDocs: 48 496\n",
      "size/len splitedDocs[0]s: 72 57\n",
      "splitedDocs Max: 1000\n",
      "splitedDocs Min: 6\n",
      "splitedDocs Sum: 372148\n",
      "#of chunks: 496\n",
      "Chunk Avg: 750.2983870967741\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:11:35.306105Z",
     "start_time": "2025-11-10T04:11:31.882478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# DONT USE THIS CODE !!! use Step3-2 Code !!!\n",
    "# Step3-1: Loading splitedDocs to chroma\n",
    "# Error case: \"Requested 367501 tokens, max 300000 tokens per request\"\n",
    "#\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "#from langchain.vectorstores import Chroma\n",
    "\n",
    "myEmbeddings = OpenAIEmbeddings()\n",
    "print(\"current OpenAIEmbeddings().model=\", myEmbeddings.model)\n",
    "myEmbeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "print(\"current OpenAIEmbeddings().model=\", myEmbeddings.model)\n",
    "\n",
    "persist_dir = \"../localdb/my_chroma_db_01\"\n",
    "myCollectionName = \"my_collection\"\n",
    "\n",
    "vdb = Chroma.from_documents(\n",
    "    splitedDocs,\n",
    "    myEmbeddings\n",
    ")\n",
    "print(\"vdb적재문서수=\", vdb._collection.count())\n"
   ],
   "id": "be42d26e0ae31da0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current OpenAIEmbeddings().model= text-embedding-ada-002\n",
      "current OpenAIEmbeddings().model= text-embedding-3-large\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Requested 367501 tokens, max 300000 tokens per request', 'type': 'max_tokens_per_request', 'param': None, 'code': 'max_tokens_per_request'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[104], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m persist_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../localdb/my_chroma_db_01\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     16\u001B[0m myCollectionName \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmy_collection\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 18\u001B[0m vdb \u001B[38;5;241m=\u001B[39m \u001B[43mChroma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43msplitedDocs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmyEmbeddings\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvdb적재문서수=\u001B[39m\u001B[38;5;124m\"\u001B[39m, vdb\u001B[38;5;241m.\u001B[39m_collection\u001B[38;5;241m.\u001B[39mcount())\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/langchain_chroma/vectorstores.py:1388\u001B[0m, in \u001B[0;36mChroma.from_documents\u001B[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001B[0m\n\u001B[1;32m   1386\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1387\u001B[0m     ids \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mid \u001B[38;5;28;01mif\u001B[39;00m doc\u001B[38;5;241m.\u001B[39mid \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(uuid\u001B[38;5;241m.\u001B[39muuid4()) \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[0;32m-> 1388\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1389\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1390\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1391\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1392\u001B[0m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1394\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpersist_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1395\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhost\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1396\u001B[0m \u001B[43m    \u001B[49m\u001B[43mport\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1397\u001B[0m \u001B[43m    \u001B[49m\u001B[43mssl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mssl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1398\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1399\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchroma_cloud_api_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchroma_cloud_api_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1400\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtenant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtenant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatabase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_settings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_settings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_configuration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_configuration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1406\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1407\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/langchain_chroma/vectorstores.py:1321\u001B[0m, in \u001B[0;36mChroma.from_texts\u001B[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001B[0m\n\u001B[1;32m   1313\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mchromadb\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbatch_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_batches\n\u001B[1;32m   1315\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m create_batches(\n\u001B[1;32m   1316\u001B[0m         api\u001B[38;5;241m=\u001B[39mchroma_collection\u001B[38;5;241m.\u001B[39m_client,\n\u001B[1;32m   1317\u001B[0m         ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[1;32m   1318\u001B[0m         metadatas\u001B[38;5;241m=\u001B[39mmetadatas,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m   1319\u001B[0m         documents\u001B[38;5;241m=\u001B[39mtexts,\n\u001B[1;32m   1320\u001B[0m     ):\n\u001B[0;32m-> 1321\u001B[0m         \u001B[43mchroma_collection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_texts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1324\u001B[0m \u001B[43m            \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1326\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1327\u001B[0m     chroma_collection\u001B[38;5;241m.\u001B[39madd_texts(texts\u001B[38;5;241m=\u001B[39mtexts, metadatas\u001B[38;5;241m=\u001B[39mmetadatas, ids\u001B[38;5;241m=\u001B[39mids)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/langchain_chroma/vectorstores.py:623\u001B[0m, in \u001B[0;36mChroma.add_texts\u001B[0;34m(self, texts, metadatas, ids, **kwargs)\u001B[0m\n\u001B[1;32m    621\u001B[0m texts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(texts)\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embedding_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 623\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_embedding_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m metadatas:\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;66;03m# fill metadatas with empty dicts if somebody\u001B[39;00m\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# did not specify metadata for all texts\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     length_diff \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(texts) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(metadatas)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/langchain_openai/embeddings/base.py:592\u001B[0m, in \u001B[0;36mOpenAIEmbeddings.embed_documents\u001B[0;34m(self, texts, chunk_size, **kwargs)\u001B[0m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001B[39;00m\n\u001B[1;32m    590\u001B[0m \u001B[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001B[39;00m\n\u001B[1;32m    591\u001B[0m engine \u001B[38;5;241m=\u001B[39m cast(\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeployment)\n\u001B[0;32m--> 592\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_len_safe_embeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    593\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunk_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    594\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/langchain_openai/embeddings/base.py:482\u001B[0m, in \u001B[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001B[0;34m(self, texts, engine, chunk_size, **kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m batched_embeddings: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mfloat\u001B[39m]] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m _iter:\n\u001B[0;32m--> 482\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokens\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m_chunk_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mclient_kwargs\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    486\u001B[0m         response \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mmodel_dump()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/openai/resources/embeddings.py:132\u001B[0m, in \u001B[0;36mEmbeddings.create\u001B[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    126\u001B[0m             embedding\u001B[38;5;241m.\u001B[39membedding \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfrombuffer(  \u001B[38;5;66;03m# type: ignore[no-untyped-call]\u001B[39;00m\n\u001B[1;32m    127\u001B[0m                 base64\u001B[38;5;241m.\u001B[39mb64decode(data), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    128\u001B[0m             )\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[0;32m--> 132\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/embeddings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEmbeddingCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    139\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCreateEmbeddingResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/openai/_base_client.py:1259\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1246\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1247\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1254\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1255\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1256\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1257\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1258\u001B[0m     )\n\u001B[0;32m-> 1259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/py09/lib/python3.9/site-packages/openai/_base_client.py:1047\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1044\u001B[0m             err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1046\u001B[0m         log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1047\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1049\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1051\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcould not resolve response (should never happen)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': 'Requested 367501 tokens, max 300000 tokens per request', 'type': 'max_tokens_per_request', 'param': None, 'code': 'max_tokens_per_request'}}"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T07:57:55.822499Z",
     "start_time": "2025-11-07T07:57:55.656885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step3-2: using package 'langchain_openai', not 'OpenAIEmbeddings'\n",
    "#          from langchain.embeddings import OpenAIEmbeddings\n",
    "#          'langchain.embeddings' deprecated, use 'langchain_openai'\n",
    "#\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "myEmbeddings = OpenAIEmbeddings()\n",
    "print(\"current OpenAIEmbeddings().model=\", myEmbeddings.model)\n",
    "myEmbeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "print(\"current OpenAIEmbeddings().model=\", myEmbeddings.model)\n",
    "\n",
    "persist_dir = \"../localdb/my_chroma_db_01\"\n",
    "myCollectionName = \"my_collection\"\n",
    "\n",
    "#\n",
    "# if u first create and add with splitedDocs to myEmbeddings, use Step3-2\n",
    "# but if u want to use already Chroma data, use Step3-3\n",
    "#\n"
   ],
   "id": "3aa52a7a37b35b92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current OpenAIEmbeddings().model= text-embedding-ada-002\n",
      "current OpenAIEmbeddings().model= text-embedding-3-large\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T07:58:12.616805Z",
     "start_time": "2025-11-07T07:57:59.323477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step3-2: Loading splitedDocs to chroma\n",
    "# chatgpt guide, use this code\n",
    "#\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "def process_in_batches(documents, batch_size=100, reset_db=True):\n",
    "    global vdb\n",
    "\n",
    "    # -- 집어 넣을 문서 확인 --\n",
    "    splitedDocsLen = len(splitedDocs)\n",
    "    print(\">> ready to insert splitedDocs, len = \", splitedDocsLen)\n",
    "\n",
    "    if splitedDocsLen == 0:\n",
    "        print(\"splitedDocs가 비어있습니다.\")\n",
    "        return 0\n",
    "\n",
    "    # -- 문서 크기를 batch_size로 나누어 확인하기\n",
    "    batchCount = splitedDocsLen // batch_size\n",
    "    if splitedDocsLen % batch_size > 0:\n",
    "        batchCount += 1\n",
    "    print(\">> batchsize is \", batch_size, \"and batchCount:\", batchCount)\n",
    "\n",
    "    # -- 문서를 batch_size로 잘라서 집어 넣기\n",
    "    for i, batch in enumerate(range(0, splitedDocsLen, batch_size)):\n",
    "        print(\">>\", i, \"th batch, \", batch, \"..\", batch + batch_size - 1, end=\"\")\n",
    "        batchDocs = splitedDocs[batch:batch + batch_size]\n",
    "        vdb.add_documents(batchDocs)\n",
    "        print(\" ++ added batchDocs len:\", len(batchDocs))\n",
    "    print(\">> vdb size:\", len( vdb.get()[\"ids\"] ))\n",
    "\n",
    "def clear_before_addDoc():\n",
    "    global vdb\n",
    "    all_ids = vdb.get()[\"ids\"]\n",
    "\n",
    "    if ( len(all_ids) == 0 ):\n",
    "        print(\">> vdb size = 0 이므로 collection delete 하지 않음.\")\n",
    "        return\n",
    "\n",
    "    # 컬렉션 내부 데이터 전체 삭제\n",
    "    print(f\">> vdb size = {len(all_ids)}, 벡터 컬렉션 데이터 삭제 시작...\", end=\"\")\n",
    "    try:\n",
    "        vdb._collection.delete(ids=all_ids)\n",
    "        print(\"++벡터 컬렉션 데이터 삭제 완료.\")\n",
    "    except Exception as e:\n",
    "        print(\"++벡터 컬렉션 삭제 실패:\", e)\n",
    "    print(\">> vdb size = \", len( vdb.get()[\"ids\"] ) )\n",
    "\n",
    "# -- main body\n",
    "\n",
    "\n",
    "# --- 기존(또는 새) 컬렉션 열기(임베딩 함수 전달) ---\n",
    "vdb = Chroma(\n",
    "    embedding_function=myEmbeddings,\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name=myCollectionName\n",
    ")\n",
    "\n",
    "print(\"[START] vdb 크기=\", len( vdb.get()[\"ids\"] ) )\n",
    "print(\">>Persist Dir:\", persist_dir)\n",
    "print(\">>myCollectionName:\", myCollectionName)\n",
    "\n",
    "clear_before_addDoc()\n",
    "process_in_batches(splitedDocs, 100, True)\n",
    "\n",
    "#print(\"vdb적재문서수=\", vdb._collection.count())\n",
    "print(\"[END] vdb 크기=\", len( vdb.get()[\"ids\"] ) )"
   ],
   "id": "f44034fab4f9e84d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] vdb 크기= 0\n",
      ">>Persist Dir: ../localdb/my_chroma_db_01\n",
      ">>myCollectionName: my_collection\n",
      ">> vdb size = 0 이므로 collection delete 하지 않음.\n",
      ">> ready to insert splitedDocs, len =  496\n",
      ">> batchsize is  100 and batchCount: 5\n",
      ">> 0 th batch,  0 .. 99 ++ added batchDocs len: 100\n",
      ">> 1 th batch,  100 .. 199 ++ added batchDocs len: 100\n",
      ">> 2 th batch,  200 .. 299 ++ added batchDocs len: 100\n",
      ">> 3 th batch,  300 .. 399 ++ added batchDocs len: 100\n",
      ">> 4 th batch,  400 .. 499 ++ added batchDocs len: 96\n",
      ">> vdb size: 496\n",
      "[END] vdb 크기= 496\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T07:59:43.685398Z",
     "start_time": "2025-11-07T07:59:43.633819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step3-3: Use splitedDocs at chroma, already Chroma Data\n",
    "#     only need: openAI API connection\n",
    "#                myEmbeddings for Chroma\n",
    "#\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vdb = Chroma(\n",
    "    embedding_function=myEmbeddings,\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name=myCollectionName\n",
    ")\n",
    "\n",
    "print(\">>Persist Dir:\", persist_dir)\n",
    "print(\">>myCollectionName:\", myCollectionName)\n",
    "print(\">>vdb 크기=\", len( vdb.get()[\"ids\"] ) )"
   ],
   "id": "5b04dca9e858e20e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Persist Dir: ../localdb/my_chroma_db_01\n",
      ">>myCollectionName: my_collection\n",
      ">>vdb 크기= 496\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T02:03:17.668722Z",
     "start_time": "2025-11-10T02:03:16.331942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step4-1:\n",
    "#\n",
    "question = '북한의 교육과정'\n",
    "resultDocs = vdb.similarity_search(question)\n",
    "print('유사문서수:', len(resultDocs))\n",
    "print( type(resultDocs), type(resultDocs[0]), type(resultDocs[0].page_content) )"
   ],
   "id": "83657a1ddcd536cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사문서수: 4\n",
      "<class 'list'> <class 'langchain_core.documents.base.Document'> <class 'str'>\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T02:08:27.743482Z",
     "start_time": "2025-11-10T02:08:27.737984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for resultDoc in resultDocs:\n",
    "    print('---' * 10)\n",
    "    print(resultDoc.metadata.get(\"page_label\"), resultDoc.page_content[:100] )\n"
   ],
   "id": "98091f048fcc221d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "284 309\t\t북한의\t학제는\t2012년\t전반적\t의무교육(유치원\t1년,\t소학교\t5년,\t초급중학교\t3년,\t고급중학교\t3년)으로\t\n",
      "개편되었는데,\t학제개편\t이전에는\t초급중학교와\t고급중학교를\t통\n",
      "------------------------------\n",
      "42 2023 북한인권보고서\n",
      "40\n",
      "명목의 교육비용이 전가되고 있는 것으로 나타났다. 교과서는 ‘교과\n",
      "서 요금’이라는 명목으로 일정 금액을 내야하는 경우가 많으며, 교\n",
      "과서가 모든 학생에\n",
      "------------------------------\n",
      "352 2023 북한인권보고서\n",
      "350\n",
      "소학교 때는 김일성, 김정일, 김정숙의 어린 시절을 배우고, 초급중\n",
      "학교에서는 혁명활동을 배우는데, 김정숙과 김정은의 내용을 학기\n",
      "마다 번갈아 가며 \n",
      "------------------------------\n",
      "351 4. 교육권\n",
      "349\n",
      "IV. 경제적·사회적·문화적 권리 I. 발간개요V. 취약계층VI. 특별사안 II. 요약III. 시민적·정치적 권리\n",
      "및 종교 집단 사이에 이해를 증진시킬 수 있도\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T02:10:35.269823Z",
     "start_time": "2025-11-10T02:10:33.903852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# 4-2: other handle of ChromaDB\n",
    "#\n",
    "vdb2 = Chroma(\n",
    "    persist_directory=persist_dir,\n",
    "    embedding_function=myEmbeddings,\n",
    "    collection_name=myCollectionName\n",
    ")\n",
    "print('문서의 수:', vdb2._collection.count())\n",
    "print( type(vdb), type(vdb2) )\n",
    "\n",
    "question = '북한의 교육과정'\n",
    "resultDocs = vdb2.similarity_search(question)\n",
    "print('유사문서수:', len(resultDocs))\n",
    "print( type(resultDocs), type(resultDocs[0]), type(resultDocs[0].page_content) )\n",
    "\n",
    "for resultDoc in resultDocs:\n",
    "    print('---' * 10)\n",
    "    print(resultDoc.metadata.get(\"page_label\"), resultDoc.page_content[:100] )\n"
   ],
   "id": "2ba8a45845e77b14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 496\n",
      "<class 'langchain_chroma.vectorstores.Chroma'> <class 'langchain_chroma.vectorstores.Chroma'>\n",
      "유사문서수: 4\n",
      "<class 'list'> <class 'langchain_core.documents.base.Document'> <class 'str'>\n",
      "------------------------------\n",
      "284 309\t\t북한의\t학제는\t2012년\t전반적\t의무교육(유치원\t1년,\t소학교\t5년,\t초급중학교\t3년,\t고급중학교\t3년)으로\t\n",
      "개편되었는데,\t학제개편\t이전에는\t초급중학교와\t고급중학교를\t통\n",
      "------------------------------\n",
      "42 2023 북한인권보고서\n",
      "40\n",
      "명목의 교육비용이 전가되고 있는 것으로 나타났다. 교과서는 ‘교과\n",
      "서 요금’이라는 명목으로 일정 금액을 내야하는 경우가 많으며, 교\n",
      "과서가 모든 학생에\n",
      "------------------------------\n",
      "352 2023 북한인권보고서\n",
      "350\n",
      "소학교 때는 김일성, 김정일, 김정숙의 어린 시절을 배우고, 초급중\n",
      "학교에서는 혁명활동을 배우는데, 김정숙과 김정은의 내용을 학기\n",
      "마다 번갈아 가며 \n",
      "------------------------------\n",
      "351 4. 교육권\n",
      "349\n",
      "IV. 경제적·사회적·문화적 권리 I. 발간개요V. 취약계층VI. 특별사안 II. 요약III. 시민적·정치적 권리\n",
      "및 종교 집단 사이에 이해를 증진시킬 수 있도\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T08:55:51.380069Z",
     "start_time": "2025-11-07T08:55:51.372642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print( vdb is vdb2 )\n",
    "print( vdb == vdb2 )\n",
    "print( id(vdb) == id(vdb2), id(vdb), id(vdb2) )\n",
    "print( vdb._collection.id == vdb2._collection.id, vdb._collection.id, vdb2._collection.id )\n",
    "print('------')\n",
    "print( type(vdb), type(db_from_file) )\n",
    "print( type(vdb._client), type(db_from_file._client))\n",
    "\n",
    "print('------')\n",
    "print(vdb._collection.name, db_from_file._collection.name)\n",
    "print(vdb._collection.name == db_from_file._collection.name) # True\n",
    "print(vdb._client.list_collections() )\n",
    "#print(vdb._client._settings.chroma_db_impl)\n",
    "#print(db_from_file._client._settings.chroma_db_impl)# 둘 다 'duckdb+parquet'\n",
    "#print(vdb._client._settings.persist_directory == db_from_file._client._settings.persist_directory)  # True\n"
   ],
   "id": "32f193101959f374",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False 4455112272 4426322992\n",
      "True ff88eb6d-51b2-41de-bc89-9d68063bce54 ff88eb6d-51b2-41de-bc89-9d68063bce54\n",
      "------\n",
      "<class 'langchain_chroma.vectorstores.Chroma'> <class 'langchain_chroma.vectorstores.Chroma'>\n",
      "<class 'chromadb.api.client.Client'> <class 'chromadb.api.client.Client'>\n",
      "------\n",
      "my_collection my_collection\n",
      "True\n",
      "[Collection(name=my_collection)]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T03:56:41.007464Z",
     "start_time": "2025-11-10T03:56:39.778707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# 4-3\n",
    "# find top 3, print similarity score\n",
    "# List[Document] -> docs[0].metadata, docs[0].page_content\n",
    "# List[Tuple[Document, float]] -> docs[0][0].metadata, docs[0][1]\n",
    "question = '북한의 교육과정'\n",
    "resultDocs = vdb2.similarity_search_with_relevance_scores(question, k=3)\n",
    "print('유사문서수:', len(resultDocs))\n",
    "print( type(resultDocs), type(resultDocs[0]) )\n",
    "print( type(resultDocs[0][0]), type(resultDocs[0][0].page_content) )\n",
    "print( type(resultDocs[0][1]), resultDocs[0][1] )\n",
    "\n",
    "for resultDoc in resultDocs:\n",
    "    print('---' * 10)\n",
    "    print(resultDoc[1], resultDoc[0].page_content[:100])\n",
    "\n",
    "for resultDoc, score in resultDocs:\n",
    "    print('---' * 10)\n",
    "    print(score, len(resultDoc.page_content) )"
   ],
   "id": "fb9801241b4ffa98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사문서수: 3\n",
      "<class 'list'> <class 'tuple'>\n",
      "<class 'langchain_core.documents.base.Document'> <class 'str'>\n",
      "<class 'float'> 0.5219001432461238\n",
      "------------------------------\n",
      "0.5219001432461238 309\t\t북한의\t학제는\t2012년\t전반적\t의무교육(유치원\t1년,\t소학교\t5년,\t초급중학교\t3년,\t고급중학교\t3년)으로\t\n",
      "개편되었는데,\t학제개편\t이전에는\t초급중학교와\t고급중학교를\t통\n",
      "------------------------------\n",
      "0.36516962706617784 2023 북한인권보고서\n",
      "40\n",
      "명목의 교육비용이 전가되고 있는 것으로 나타났다. 교과서는 ‘교과\n",
      "서 요금’이라는 명목으로 일정 금액을 내야하는 경우가 많으며, 교\n",
      "과서가 모든 학생에\n",
      "------------------------------\n",
      "0.36082879669749535 2023 북한인권보고서\n",
      "350\n",
      "소학교 때는 김일성, 김정일, 김정숙의 어린 시절을 배우고, 초급중\n",
      "학교에서는 혁명활동을 배우는데, 김정숙과 김정은의 내용을 학기\n",
      "마다 번갈아 가며 \n",
      "------------------------------\n",
      "0.5219001432461238 187\n",
      "------------------------------\n",
      "0.36516962706617784 866\n",
      "------------------------------\n",
      "0.36082879669749535 867\n"
     ]
    }
   ],
   "execution_count": 96
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
